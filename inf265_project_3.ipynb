{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 8216967,
     "sourceType": "datasetVersion",
     "datasetId": 4870498
    }
   ],
   "dockerImageVersionId": 30699,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import string\n",
    "import copy\n",
    "\n",
    "seed = 265\n",
    "torch.manual_seed(seed);"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:24:15.543643Z",
     "iopub.execute_input": "2024-05-02T07:24:15.544361Z",
     "iopub.status.idle": "2024-05-02T07:24:21.599203Z",
     "shell.execute_reply.started": "2024-05-02T07:24:15.544330Z",
     "shell.execute_reply": "2024-05-02T07:24:21.598294Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:07:51.184744400Z",
     "start_time": "2024-05-02T11:07:50.314174100Z"
    }
   },
   "execution_count": 120,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Helper functions for training:\n",
    "\n",
    "def set_device(device=None):\n",
    "    \"\"\"\n",
    "    Helper function to set device\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = (\n",
    "            torch.device('cuda') if torch.cuda.is_available()\n",
    "            else torch.device('cpu'))\n",
    "        print(f\"On device {device}.\")\n",
    "    return device\n",
    "\n",
    "def train(n_epochs, optimizer, model, loss_fn, train_loader, val_loader=None, device=None):\n",
    "    device = set_device(device)\n",
    "\n",
    "    n_batch_train = len(train_loader)\n",
    "    if val_loader:\n",
    "        n_batch_val = len(val_loader)\n",
    "    losses_train = []\n",
    "    losses_val = []\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for train_contexts, train_targets in train_loader:\n",
    "\n",
    "            train_contexts = train_contexts.to(device=device)\n",
    "            train_targets = train_targets.to(device=device)\n",
    "\n",
    "            train_outputs = model(train_contexts)\n",
    "\n",
    "            loss = loss_fn(train_outputs, train_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        avg_loss_train = loss_train / n_batch_train\n",
    "        losses_train.append(avg_loss_train)\n",
    "\n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            print('{}  |  Epoch {}  |  Training loss {:.5f}'.format(\n",
    "                datetime.now().time().strftime(\"%H:%M:%S\"), epoch, avg_loss_train))\n",
    "        \n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            loss_val = 0.0\n",
    "            n_batch_val = len(val_loader)\n",
    "            with torch.no_grad():\n",
    "                for val_contexts, val_targets in val_loader:\n",
    "                    val_contexts = val_contexts.to(device=device)\n",
    "                    val_targets = val_targets.to(device=device)\n",
    "\n",
    "                    val_outputs = model(val_contexts)\n",
    "                    val_loss = loss_fn(val_outputs, val_targets)\n",
    "                    loss_val += val_loss.item()\n",
    "            \n",
    "            avg_loss_val = loss_val / n_batch_val\n",
    "            losses_val.append(avg_loss_val) \n",
    "            \n",
    "            if epoch % 5 == 0 or epoch == 1:\n",
    "                print('{}  |  Epoch {}  |  Validation loss {:.5f}'.format(\n",
    "                    datetime.now().strftime(\"%H:%M:%S\"), epoch, avg_loss_val))\n",
    "            \n",
    "            model.train()\n",
    "            \n",
    "    return losses_train, losses_val\n",
    "\n",
    "\n",
    "def compute_accuracy(model, loader, device=None):\n",
    "    model.eval()\n",
    "    device = set_device(device)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for contexts, targets in loader:\n",
    "            contexts = contexts.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "\n",
    "            outputs = model(contexts)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += len(targets)\n",
    "            correct += int((predicted == targets).sum())\n",
    "\n",
    "    acc =  correct / total\n",
    "    return acc"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:24:21.601147Z",
     "iopub.execute_input": "2024-05-02T07:24:21.601632Z",
     "iopub.status.idle": "2024-05-02T07:24:21.618087Z",
     "shell.execute_reply.started": "2024-05-02T07:24:21.601604Z",
     "shell.execute_reply": "2024-05-02T07:24:21.617122Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:07:51.219107400Z",
     "start_time": "2024-05-02T11:07:51.179978600Z"
    }
   },
   "execution_count": 121,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "data_path = 'textdata/'\n",
    "min_freq = 100\n",
    "device = set_device()\n",
    "CONTEXT_SIZE = 2 # two tokens on either side for cbow."
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:24:21.619414Z",
     "iopub.execute_input": "2024-05-02T07:24:21.619782Z",
     "iopub.status.idle": "2024-05-02T07:24:21.668913Z",
     "shell.execute_reply.started": "2024-05-02T07:24:21.619751Z",
     "shell.execute_reply": "2024-05-02T07:24:21.667945Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:07:51.297880900Z",
     "start_time": "2024-05-02T11:07:51.220120600Z"
    }
   },
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On device cpu.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Helper functions for text pre-processing:\n",
    "# Credit to the text data tutorial for this cell:\n",
    "def read_files(path=data_path + \"data_train/\"):\n",
    "    files = os.listdir(path)\n",
    "    \n",
    "    lines = []\n",
    "    \n",
    "    for file in files:\n",
    "        with open(path + file) as f:\n",
    "            lines += f.readlines()\n",
    "    \n",
    "    return lines\n",
    "    \n",
    "def tokenize(lines, tokenizer=tokenizer):\n",
    "    list_text = []\n",
    "    for line in lines:\n",
    "        list_text += tokenizer(line)\n",
    "    return list_text\n",
    "\n",
    "def yield_tokens(lines, tokenizer=tokenizer):\n",
    "    \"\"\"\n",
    "    Yield tokens, ignoring names and digits to build vocabulary\n",
    "    \"\"\"\n",
    "    # Match any word containing digit\n",
    "    no_digits = r'\\w*[0-9]+\\w*'\n",
    "    # Match word containing a uppercase \n",
    "    no_names = r'\\w*[A-Z]+\\w*'\n",
    "    # Match any sequence containing more than one space\n",
    "    no_spaces = r'\\s+'\n",
    "    \n",
    "    for line in lines:\n",
    "        line = re.sub(no_digits, ' ', line)\n",
    "        line = re.sub(no_names, ' ', line)\n",
    "        line = re.sub(no_spaces, ' ', line)\n",
    "        yield tokenizer(line)\n",
    "\n",
    "def count_freqs(words, vocab):\n",
    "    \"\"\"\n",
    "    Count occurrences of each word in vocabulary in the data\n",
    "    \n",
    "    Useful to get some insight on the data and to compute loss weights\n",
    "    \"\"\"\n",
    "    freqs = torch.zeros(len(vocab), dtype=torch.int)\n",
    "    for w in words:\n",
    "        freqs[vocab[w]] += 1\n",
    "    return freqs\n",
    "\n",
    "def count_freqs_int(int_targets, vocab):\n",
    "    \"\"\"\n",
    "    Count occurrences of each word index in the data\n",
    "    \n",
    "    This function is adjusted to work directly with word indices that are already integers.\n",
    "    Useful to get some insight on the data and to compute loss weights.\n",
    "\n",
    "    Parameters:\n",
    "    - int_targets: a list of integer indices corresponding to words.\n",
    "    - vocab_size: the size of the vocabulary.\n",
    "\n",
    "    Returns:\n",
    "    - freqs: a tensor of frequencies for each word index.\n",
    "    \"\"\"\n",
    "    freqs = torch.zeros(len(vocab), dtype=torch.int)\n",
    "    for index in int_targets:\n",
    "        freqs[index] += 1\n",
    "    return freqs\n",
    "\n",
    "def create_vocabulary(lines, min_freq=min_freq):\n",
    "    \"\"\"\n",
    "    Create a vocabulary (list of known tokens) from a list of strings\n",
    "    \"\"\"\n",
    "    # vocab contains the vocabulary found in the data, associating an index to each word\n",
    "    vocab = build_vocab_from_iterator(yield_tokens(lines), min_freq=min_freq, specials=[\"<unk>\"])\n",
    "    # Since we removed all words with an uppercase when building the vocabulary, we skipped the word \"I\"\n",
    "    vocab.append_token(\"i\")\n",
    "    # Value of default index. This index will be returned when OOV (Out Of Vocabulary) token is queried.\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "    return vocab"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:24:21.671157Z",
     "iopub.execute_input": "2024-05-02T07:24:21.671471Z",
     "iopub.status.idle": "2024-05-02T07:24:21.683971Z",
     "shell.execute_reply.started": "2024-05-02T07:24:21.671446Z",
     "shell.execute_reply": "2024-05-02T07:24:21.683113Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:07:51.325183800Z",
     "start_time": "2024-05-02T11:07:51.287793Z"
    }
   },
   "execution_count": 123,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ----------------------- Tokenize texts -------------------------------\n",
    "# Load tokenized versions of texts if you have already generated it\n",
    "# Otherwise, create it and save it\n",
    "token_path = 'tokens/'\n",
    "os.makedirs(token_path, exist_ok=True)\n",
    "\n",
    "if os.path.isfile(token_path + \"words_train.pt\"):\n",
    "    words_train = torch.load(token_path + \"words_train.pt\")\n",
    "    words_val = torch.load(token_path + \"words_val.pt\")\n",
    "    words_test = torch.load(token_path + \"words_test.pt\")\n",
    "else:\n",
    "    # Get lists of strings, one for each line in each .txt files in 'datapath' \n",
    "    lines_books_train = read_files(data_path + 'data_train/')\n",
    "    lines_books_val = read_files(data_path + 'data_val/')\n",
    "    lines_books_test = read_files(data_path + 'data_test/')\n",
    "\n",
    "    # List of words contained in the dataset\n",
    "    words_train = tokenize(lines_books_train)\n",
    "    words_val = tokenize(lines_books_val)\n",
    "    words_test = tokenize(lines_books_test)\n",
    "    \n",
    "    torch.save(words_train , token_path + \"words_train.pt\")\n",
    "    torch.save(words_val , token_path + \"words_val.pt\")\n",
    "    torch.save(words_test , token_path + \"words_test.pt\")\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------- Create vocabulary ----------------------------\n",
    "vocab_path = 'vocabs/'\n",
    "os.makedirs(vocab_path, exist_ok=True)\n",
    "vocab_name = \"vocabulary.pt\"\n",
    "# Load vocabulary if you have already generated it\n",
    "# Otherwise, create it and save it\n",
    "if os.path.isfile(vocab_path + vocab_name):\n",
    "    vocab = torch.load(vocab_path + vocab_name)\n",
    "else:\n",
    "    # Create vocabulary based on the words in the training dataset\n",
    "    vocab = create_vocabulary(lines_books_train, min_freq=min_freq)\n",
    "    torch.save(vocab, vocab_path + vocab_name)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-05-02T07:24:21.685174Z",
     "iopub.execute_input": "2024-05-02T07:24:21.685429Z",
     "iopub.status.idle": "2024-05-02T07:24:23.662291Z",
     "shell.execute_reply.started": "2024-05-02T07:24:21.685408Z",
     "shell.execute_reply": "2024-05-02T07:24:23.661419Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:07:52.259053500Z",
     "start_time": "2024-05-02T11:07:51.317434800Z"
    }
   },
   "execution_count": 124,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ------------------------ Vocab analysis ------------------------------\n",
    "VOCAB_SIZE = len(vocab)\n",
    "print(\"Total number of words in the training dataset:     \", len(words_train))\n",
    "print(\"Total number of words in the validation dataset:   \", len(words_val))\n",
    "print(\"Total number of words in the test dataset:         \", len(words_test))\n",
    "print(\"Number of distinct words in the training dataset:  \", len(set(words_train)))\n",
    "print(\"Number of distinct words kept (vocabulary size):   \", VOCAB_SIZE)\n",
    "\n",
    "freqs = count_freqs(words_train, vocab)\n",
    "print(\"Twenty first words in the vocabulary and their occurences:\\n\", [(f.item(), w) for (f, w)  in zip(freqs, vocab.lookup_tokens(range(20)))])\n",
    "print(\"Twenty last words in the vocabulary and their occurences:\\n\", [(f.item(), w) for (f, w)  in zip(freqs[-20:], vocab.lookup_tokens(range((len(vocab) - 20), len(vocab))))])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:24:23.663584Z",
     "iopub.execute_input": "2024-05-02T07:24:23.663968Z",
     "iopub.status.idle": "2024-05-02T07:24:58.409602Z",
     "shell.execute_reply.started": "2024-05-02T07:24:23.663934Z",
     "shell.execute_reply": "2024-05-02T07:24:58.408680Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:08:25.839688200Z",
     "start_time": "2024-05-02T11:07:52.208277Z"
    }
   },
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the training dataset:      2684706\n",
      "Total number of words in the validation dataset:    49526\n",
      "Total number of words in the test dataset:          124152\n",
      "Number of distinct words in the training dataset:   52105\n",
      "Number of distinct words kept (vocabulary size):    1880\n",
      "Twenty first words in the vocabulary and their occurences:\n",
      " [(433907, '<unk>'), (182537, ','), (151278, 'the'), (123727, '.'), (82289, 'and'), (65661, 'of'), (62763, 'to'), (49230, 'a'), (41477, 'in'), (31052, 'that'), (37167, 'he'), (29046, 'was'), (26508, 'his'), (26354, 'it'), (20862, 'with'), (20159, 'had'), (19965, 'is'), (15692, 'not'), (16593, 'as'), (15705, 'on')]\n",
      "Twenty last words in the vocabulary and their occurences:\n",
      " [(102, 'astonished'), (101, 'authority'), (105, 'bourgeois'), (101, 'chain'), (102, 'crossing'), (101, 'divided'), (100, 'eaten'), (116, 'elder'), (101, 'ends'), (108, 'gradually'), (102, 'instinct'), (100, 'mounted'), (100, 'pistol'), (102, 'pot'), (103, 'pride'), (100, 'slipped'), (100, 'station-master'), (182, 'thank'), (100, 'wounds'), (22996, 'i')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Context/target dataset creation, inspired by tutorial"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def create_dataset(text, vocab, context_size=CONTEXT_SIZE):\n",
    "    \"\"\"\n",
    "    Create a PyTorch dataset of context/target pairs from a text\n",
    "    \"\"\"\n",
    "\n",
    "    # Define punctuation symbols\n",
    "    string_punctuations = string.punctuation\n",
    "    punctuations = [vocab[p] for p in string_punctuations\n",
    "               if vocab[p] != 0]\n",
    "    \n",
    "    # Transform the text into a list of integers from vocabulary\n",
    "    txt = [vocab[w] for w in text]\n",
    "    \n",
    "    n_text = len(txt)\n",
    "\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    for i in range(n_text - context_size*2):\n",
    "        # Word directly after the start of context is the target.\n",
    "        target = txt[i + context_size]\n",
    "        # Skip targets that are unknown:\n",
    "        if vocab.lookup_token(target) != '<unk>' and target not in punctuations:\n",
    "            # Context before target\n",
    "            context_before = txt[i:i + context_size]\n",
    "\n",
    "            # Context after the target\n",
    "            context_behind = txt[i + context_size + 1: i + context_size*2 + 1]\n",
    "\n",
    "            targets.append(target)\n",
    "            contexts.append(torch.tensor(context_before + context_behind))\n",
    "\n",
    "    # Convert contexts and targets into PyTorch tensors and stack for dataset formation.\n",
    "    contexts = torch.stack(contexts)\n",
    "    targets = torch.tensor(targets)\n",
    "    \n",
    "    # Create a PyTorch dataset from these context/target pairs\n",
    "    return TensorDataset(contexts, targets)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-05-02T07:24:58.410736Z",
     "iopub.execute_input": "2024-05-02T07:24:58.411018Z",
     "iopub.status.idle": "2024-05-02T07:24:58.419736Z",
     "shell.execute_reply.started": "2024-05-02T07:24:58.410993Z",
     "shell.execute_reply": "2024-05-02T07:24:58.418837Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:08:25.863766Z",
     "start_time": "2024-05-02T11:08:25.839688200Z"
    }
   },
   "execution_count": 126,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_path = 'dataset/'\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "def load_dataset(words, vocab, fname):\n",
    "    \"\"\"\n",
    "    Load dataset if already generated, otherwise, create it and save it\n",
    "    \"\"\"\n",
    "    # If already generated\n",
    "    if os.path.isfile(dataset_path + fname):\n",
    "        dataset = torch.load(dataset_path + fname)\n",
    "    else:\n",
    "        # Create context / target dataset based on the list of strings\n",
    "        dataset = create_dataset(words, vocab)\n",
    "        torch.save(dataset, dataset_path + fname)\n",
    "    return dataset\n",
    "\n",
    "data_train = load_dataset(words_train, vocab, \"data_train.pt\")\n",
    "data_val = load_dataset(words_val, vocab, \"data_val.pt\")\n",
    "data_test = load_dataset(words_test, vocab, \"data_test.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-05-02T07:24:58.420753Z",
     "iopub.execute_input": "2024-05-02T07:24:58.421011Z",
     "iopub.status.idle": "2024-05-02T07:24:58.487639Z",
     "shell.execute_reply.started": "2024-05-02T07:24:58.420989Z",
     "shell.execute_reply": "2024-05-02T07:24:58.486635Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:08:25.941860700Z",
     "start_time": "2024-05-02T11:08:25.846322800Z"
    }
   },
   "execution_count": 127,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"The training data has {len(data_train)} entries.\")\n",
    "print(f\"The validation data has {len(data_val)} entries.\")\n",
    "print(f\"The test data has {len(data_test)} entries.\")"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-05-02T07:24:58.488988Z",
     "iopub.execute_input": "2024-05-02T07:24:58.489832Z",
     "iopub.status.idle": "2024-05-02T07:24:58.494954Z",
     "shell.execute_reply.started": "2024-05-02T07:24:58.489795Z",
     "shell.execute_reply": "2024-05-02T07:24:58.494123Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:08:25.970739Z",
     "start_time": "2024-05-02T11:08:25.933131300Z"
    }
   },
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data has 1916842 entries.\n",
      "The validation data has 36218 entries.\n",
      "The test data has 83643 entries.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple CBOW model\n",
    "Inspired by this tutorial: https://www.youtube.com/watch?v=Rqh4SRcZuDA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class SimpleCBOW(nn.Module):\n",
    "    def __init__(self, emb_dim=16, vocab_size=VOCAB_SIZE):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.fc = nn.Linear(emb_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding(x).mean(1).squeeze(1) # batch_size x emb_dim\n",
    "        return self.fc(embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-05-02T07:24:58.498715Z",
     "iopub.execute_input": "2024-05-02T07:24:58.499078Z",
     "iopub.status.idle": "2024-05-02T07:24:58.506034Z",
     "shell.execute_reply.started": "2024-05-02T07:24:58.499037Z",
     "shell.execute_reply": "2024-05-02T07:24:58.505236Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:08:25.997235200Z",
     "start_time": "2024-05-02T11:08:25.939760500Z"
    }
   },
   "execution_count": 129,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Larger CBOW model\n",
    "\n",
    "An attempt to see if a more complex model performs better, includes dropout, batch normalisation and an extra fully connected layer."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class LargerCBOW(nn.Module):\n",
    "    def __init__(self, emb_dim=32, vocab_size=VOCAB_SIZE, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc1 = nn.Linear(emb_dim, 256)\n",
    "        self.batchnorm256 = nn.BatchNorm1d(256)\n",
    "        self.out = nn.Linear(256, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding(x).mean(1).squeeze(1)\n",
    "        embeddings = F.relu(self.fc1(embeddings))\n",
    "        embeddings = self.batchnorm256(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return self.out(embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-05-02T07:24:58.507159Z",
     "iopub.execute_input": "2024-05-02T07:24:58.507438Z",
     "iopub.status.idle": "2024-05-02T07:24:58.516516Z",
     "shell.execute_reply.started": "2024-05-02T07:24:58.507415Z",
     "shell.execute_reply": "2024-05-02T07:24:58.515757Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:08:26.015389700Z",
     "start_time": "2024-05-02T11:08:25.945493600Z"
    }
   },
   "execution_count": 130,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculating training label frequencies for class weights"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "training_freqs = count_freqs_int(data_train[:][1], vocab)\n",
    "\n",
    "# Here we see that the two first tokens in the vocabulary,\n",
    "# \"<unk>\" and \",\" have 0 counts in the target set\n",
    "print(f'Updated frequencies for new dataset: {training_freqs[:10]}')\n",
    "\n",
    "training_freqs = torch.tensor(training_freqs, dtype=torch.float)\n",
    "\n",
    "\n",
    "total_samples = training_freqs.sum()\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = total_samples / training_freqs\n",
    "\n",
    "# Remove inf's caused by division by zero\n",
    "class_weights = torch.tensor([w if w != float('inf') else 0 for w in class_weights]).to(device)\n",
    "\n",
    "# Create logarithmically scaled weights to reduce magnitude\n",
    "log_weights = torch.log(class_weights)\n",
    "\n",
    "# Again, remove -inf's caused by logarithm\n",
    "log_weights = torch.tensor([w if w != float('-inf') else 0 for w in log_weights]).to(device)\n",
    "\n",
    "print(f'Class weights sample: {class_weights[:10]}')\n",
    "print(f'Largest class weight: {torch.max(class_weights):.2f}')\n",
    "\n",
    "print(f'Logarithmically scaled weights sample: {log_weights[:10]}')\n",
    "print(f'Largest logarithmic weight: {torch.max(log_weights):.2f}')\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:24:58.517735Z",
     "iopub.execute_input": "2024-05-02T07:24:58.518112Z",
     "iopub.status.idle": "2024-05-02T07:25:27.635643Z",
     "shell.execute_reply.started": "2024-05-02T07:24:58.518077Z",
     "shell.execute_reply": "2024-05-02T07:25:27.634775Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:08:50.132053800Z",
     "start_time": "2024-05-02T11:08:25.953602300Z"
    }
   },
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated frequencies for new dataset: tensor([     0,      0, 151278,      0,  82288,  65661,  62763,  49230,  41477,\n",
      "         31052], dtype=torch.int32)\n",
      "Class weights sample: tensor([ 0.0000,  0.0000, 12.6710,  0.0000, 23.2943, 29.1930, 30.5410, 38.9365,\n",
      "        46.2146, 61.7301])\n",
      "Largest class weight: 19168.42\n",
      "Logarithmically scaled weights sample: tensor([0.0000, 0.0000, 2.5393, 0.0000, 3.1482, 3.3739, 3.4191, 3.6619, 3.8333,\n",
      "        4.1228])\n",
      "Largest logarithmic weight: 9.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxba\\AppData\\Local\\Temp\\ipykernel_24108\\192657366.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  training_freqs = torch.tensor(training_freqs, dtype=torch.float)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training all CBOWS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def run_cbows(first, second, train_loader, val_loader):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for model in first:\n",
    "        if not os.path.isfile(cbow_path + model.__class__.__name__ + \"no_weights.pt\"):\n",
    "            print(f'Training model: {model.__class__.__name__ + \"no_weights\"}')\n",
    "            optim = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            losses_train, losses_val = train(20, optim, model, loss_fn, train_loader, val_loader, device=device)\n",
    "            train_losses.append(losses_train)\n",
    "            val_losses.append(losses_val)\n",
    "\n",
    "            torch.save(model, cbow_path + model.__class__.__name__ + \"no_weights.pt\" )\n",
    "        \n",
    "        \n",
    "    for model in second:\n",
    "        if not os.path.isfile(cbow_path + model.__class__.__name__ + \"with_weights.pt\"):\n",
    "            print(f'Training model: {model.__class__.__name__ + \"with_weights\"}')\n",
    "            optim = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "            loss_fn = nn.CrossEntropyLoss(weight=log_weights)\n",
    "            losses_train, losses_val = train(20, optim, model, loss_fn, train_loader, val_loader, device=device)\n",
    "            train_losses.append(losses_train)\n",
    "            val_losses.append(losses_val)\n",
    "\n",
    "\n",
    "            torch.save(model, cbow_path + model.__class__.__name__ + \"with_weights.pt\")\n",
    "            \n",
    "    return train_losses, val_losses"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:27.636495Z",
     "iopub.execute_input": "2024-05-02T07:25:27.636757Z",
     "iopub.status.idle": "2024-05-02T07:25:27.646476Z",
     "shell.execute_reply.started": "2024-05-02T07:25:27.636734Z",
     "shell.execute_reply": "2024-05-02T07:25:27.645471Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:08:50.185216200Z",
     "start_time": "2024-05-02T11:08:50.130304500Z"
    }
   },
   "execution_count": 132,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "cbow_path = 'models/cbow/'\n",
    "    \n",
    "# Run four experiments, where cbow 1 and 2 will be without class weights,\n",
    "# while cbow 3 and 4 will be with class weights.\n",
    "cbow1 = SimpleCBOW(emb_dim=16, vocab_size=VOCAB_SIZE).to(device)\n",
    "cbow2 = LargerCBOW(emb_dim=32, vocab_size=VOCAB_SIZE).to(device)\n",
    "cbow3 = SimpleCBOW(emb_dim=16, vocab_size=VOCAB_SIZE).to(device)\n",
    "cbow4 = LargerCBOW(emb_dim=32, vocab_size=VOCAB_SIZE).to(device)\n",
    "\n",
    "    \n",
    "no_weights_cbows = [cbow1, cbow2]\n",
    "with_weights_cbows = [cbow3, cbow4]\n",
    "\n",
    "\n",
    "train_loader = DataLoader(data_train, batch_size=128)\n",
    "val_loader = DataLoader(data_val, batch_size=128)\n",
    "\n",
    "\n",
    "train_losses, val_losses = run_cbows(no_weights_cbows, with_weights_cbows, train_loader, val_loader)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:27.647595Z",
     "iopub.execute_input": "2024-05-02T07:25:27.647895Z",
     "iopub.status.idle": "2024-05-02T07:25:27.687811Z",
     "shell.execute_reply.started": "2024-05-02T07:25:27.647864Z",
     "shell.execute_reply": "2024-05-02T07:25:27.686997Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:08:50.313672400Z",
     "start_time": "2024-05-02T11:08:50.139438600Z"
    }
   },
   "execution_count": 133,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting the best CBOW"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "def evaluate_and_select_cbow(cbows, cbow_names, model_path, val_loader):\n",
    "    accs = []\n",
    "\n",
    "    for cbow in cbows:\n",
    "        acc = compute_accuracy(cbow, val_loader, device=device)\n",
    "        accs.append(acc)\n",
    "    \n",
    "    model_idx = accs.index(max(accs))\n",
    "    print(f'Max accuracy: {accs[model_idx]:.3f}, selected model: model: {model_idx + 1}: {cbow_names[model_idx]}', end='\\n\\n')\n",
    "    print('All accuracies: \\n' + '\\n'.join([f'{cbow_name} achieved {round(acc, 3)}' for cbow_name, acc in zip(cbow_names, accs)]))\n",
    "    return cbows[model_idx]\n",
    "\n",
    "cbow1 = torch.load(cbow_path + 'SimpleCBOWno_weights.pt', map_location=device)\n",
    "cbow2 = torch.load(cbow_path + 'LargerCBOWno_weights.pt', map_location=device)\n",
    "cbow3 = torch.load(cbow_path + 'SimpleCBOWwith_weights.pt', map_location=device)\n",
    "cbow4 = torch.load(cbow_path + 'LargerCBOWwith_weights.pt', map_location=device)\n",
    "\n",
    "\n",
    "cbows = [cbow1, cbow2, cbow3, cbow4]\n",
    "cbow_names = ['SimpleCBOW', 'LargerCBOW', 'SimpleCBOW_weights', 'LargerCBOW_weights']\n",
    "val_loader = DataLoader(data_val, batch_size=128)\n",
    "selected_cbow = evaluate_and_select_cbow(cbows, cbow_names, cbow_path, val_loader)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:27.688906Z",
     "iopub.execute_input": "2024-05-02T07:25:27.689187Z",
     "iopub.status.idle": "2024-05-02T07:25:29.639819Z",
     "shell.execute_reply.started": "2024-05-02T07:25:27.689164Z",
     "shell.execute_reply": "2024-05-02T07:25:29.638905Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:08:53.037489900Z",
     "start_time": "2024-05-02T11:08:50.165933700Z"
    }
   },
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy: 0.189, selected model: model: 2: LargerCBOW\n",
      "\n",
      "All accuracies: \n",
      "SimpleCBOW achieved 0.166\n",
      "LargerCBOW achieved 0.189\n",
      "SimpleCBOW_weights achieved 0.151\n",
      "LargerCBOW_weights achieved 0.176\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# It seems like the losses aren't stabilising yet - train the two larger cbow models for more epochs\n",
    "if not os.path.isfile(cbow_path + cbow2.__class__.__name__ + \"no_weights50epochs.pt\"):\n",
    "    no_weights = cbow2\n",
    "    optim = torch.optim.Adam(no_weights.parameters(), lr=0.005)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    losses = train(30, optim, no_weights, loss_fn, train_loader, val_loader)\n",
    "\n",
    "    torch.save(no_weights, cbow_path + no_weights.__class__.__name__+ \"no_weights50epochs.pt\")\n",
    "else:\n",
    "    no_weights = torch.load(cbow_path + cbow2.__class__.__name__ + \"no_weights50epochs.pt\", map_location=device)\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.isfile(cbow_path + cbow4.__class__.__name__ + \"with_weights50epochs.pt\"):\n",
    "    with_weights = cbow4\n",
    "    optim = torch.optim.Adam(with_weights.parameters(), lr=0.005)\n",
    "    loss_fn = nn.CrossEntropyLoss(log_weights)\n",
    "    losses = train(30, optim, with_weights, loss_fn, train_loader, val_loader)\n",
    "\n",
    "    torch.save(with_weights, cbow_path + with_weights.__class__.__name__+ \"with_weights50epochs.pt\")\n",
    "else:\n",
    "    with_weights = torch.load(cbow_path + cbow4.__class__.__name__ + \"with_weights50epochs.pt\", map_location=device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:29.640939Z",
     "iopub.execute_input": "2024-05-02T07:25:29.641206Z",
     "iopub.status.idle": "2024-05-02T07:25:29.657645Z",
     "shell.execute_reply.started": "2024-05-02T07:25:29.641184Z",
     "shell.execute_reply": "2024-05-02T07:25:29.656554Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:08:53.146154300Z",
     "start_time": "2024-05-02T11:08:53.034090900Z"
    }
   },
   "execution_count": 135,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cbows.append(no_weights)\n",
    "cbows.append(with_weights)\n",
    "cbow_names.append('LargerCBOW50epochs')\n",
    "cbow_names.append('LargerCBOW50epochs_weights')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:29.659093Z",
     "iopub.execute_input": "2024-05-02T07:25:29.659866Z",
     "iopub.status.idle": "2024-05-02T07:25:29.664614Z",
     "shell.execute_reply.started": "2024-05-02T07:25:29.659829Z",
     "shell.execute_reply": "2024-05-02T07:25:29.663710Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:08:53.188228900Z",
     "start_time": "2024-05-02T11:08:53.056529200Z"
    }
   },
   "execution_count": 136,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Now see if performance improved after further training\n",
    "selected_cbow = evaluate_and_select_cbow(cbows, cbow_names, cbow_path, val_loader)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:29.665690Z",
     "iopub.execute_input": "2024-05-02T07:25:29.665965Z",
     "iopub.status.idle": "2024-05-02T07:25:31.911397Z",
     "shell.execute_reply.started": "2024-05-02T07:25:29.665935Z",
     "shell.execute_reply": "2024-05-02T07:25:31.910314Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:08:57.504302400Z",
     "start_time": "2024-05-02T11:08:53.062607300Z"
    }
   },
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy: 0.189, selected model: model: 2: LargerCBOW\n",
      "\n",
      "All accuracies: \n",
      "SimpleCBOW achieved 0.166\n",
      "LargerCBOW achieved 0.189\n",
      "SimpleCBOW_weights achieved 0.151\n",
      "LargerCBOW_weights achieved 0.176\n",
      "LargerCBOW50epochs achieved 0.186\n",
      "LargerCBOW50epochs_weights achieved 0.171\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting final metrics of selected CBOW:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(seed)\n",
    "train_loader = DataLoader(data_train, batch_size=128)\n",
    "val_loader = DataLoader(data_val, batch_size=128)\n",
    "test_loader = DataLoader(data_test, batch_size=128)\n",
    "\n",
    "train_acc = compute_accuracy(selected_cbow, train_loader, device=device)\n",
    "val_acc = compute_accuracy(selected_cbow, val_loader, device=device)\n",
    "test_acc = compute_accuracy(selected_cbow, test_loader, device=device)\n",
    "\n",
    "print(f'Final model accuracy on train data: {train_acc:.3f}')\n",
    "print(f'Final model accuracy on val data: {val_acc:.3f}')\n",
    "print(f'Final model accuracy on test data: {test_acc:.3f}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:31.912717Z",
     "iopub.execute_input": "2024-05-02T07:25:31.913048Z",
     "iopub.status.idle": "2024-05-02T07:25:53.793369Z",
     "shell.execute_reply.started": "2024-05-02T07:25:31.913020Z",
     "shell.execute_reply": "2024-05-02T07:25:53.792435Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:45.567932700Z",
     "start_time": "2024-05-02T11:08:57.502849700Z"
    }
   },
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model accuracy on train data: 0.197\n",
      "Final model accuracy on val data: 0.189\n",
      "Final model accuracy on test data: 0.210\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Create embeddings from selected model\n",
    "embeddings_path = '/kaggle/working/embedding/'\n",
    "os.makedirs(embeddings_path, exist_ok=True)\n",
    "if not os.path.isfile(embeddings_path + \"unnormalized_embeddings.pt\"):\n",
    "    word_embeddings = selected_cbow.embedding.weight.data\n",
    "    torch.save(word_embeddings, embeddings_path + \"unnormalized_embeddings.pt\")\n",
    "else:\n",
    "    word_embeddings = torch.load(embeddings_path + \"unnormalized_embeddings.pt\", map_location=device)\n",
    "\n",
    "if not os.path.isfile(embeddings_path + \"normalized_embeddings.pt\"):\n",
    "    normalized_embeddings = F.normalize(word_embeddings, p=2, dim=1)\n",
    "    torch.save(normalized_embeddings, embeddings_path + \"normalized_embeddings.pt\")\n",
    "else:\n",
    "    normalized_embeddings = torch.load(embeddings_path + \"normalized_embeddings.pt\", map_location=device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:53.794491Z",
     "iopub.execute_input": "2024-05-02T07:25:53.794756Z",
     "iopub.status.idle": "2024-05-02T07:25:53.803607Z",
     "shell.execute_reply.started": "2024-05-02T07:25:53.794733Z",
     "shell.execute_reply": "2024-05-02T07:25:53.802713Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:45.632334900Z",
     "start_time": "2024-05-02T11:09:45.563367500Z"
    }
   },
   "execution_count": 139,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "word_ls =  ['me', 'white', 'man', 'have', 'be', 'child', 'yes', 'what',\n",
    "           'cold', 'wet', 'ran', 'convinced', 'scare']"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:53.804727Z",
     "iopub.execute_input": "2024-05-02T07:25:53.805135Z",
     "iopub.status.idle": "2024-05-02T07:25:53.819428Z",
     "shell.execute_reply.started": "2024-05-02T07:25:53.805106Z",
     "shell.execute_reply": "2024-05-02T07:25:53.818617Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:45.683382500Z",
     "start_time": "2024-05-02T11:09:45.579151Z"
    }
   },
   "execution_count": 140,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Convert selected words to indices\n",
    "word_indices = [vocab[word] for word in word_ls]\n",
    "selected_embeddings = normalized_embeddings[word_indices]\n",
    "\n",
    "# Compute the cosine similarity between the selected words and all words in the vocabulary\n",
    "cosine_similarities = torch.matmul(selected_embeddings, normalized_embeddings.transpose(0, 1))\n",
    "\n",
    "# For each word, find the 10 most similar words\n",
    "top_similar_words = []\n",
    "for i, word in enumerate(word_ls):\n",
    "    similarities = cosine_similarities[i]\n",
    "    # We skip the first one because it will be the word itself with a similarity of 1.\n",
    "    top_indices = similarities.topk(11).indices[1:]\n",
    "    similar_words = [vocab.lookup_token(index) for index in top_indices]\n",
    "    top_similar_words.append(similar_words)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:53.820464Z",
     "iopub.execute_input": "2024-05-02T07:25:53.820748Z",
     "iopub.status.idle": "2024-05-02T07:25:53.897383Z",
     "shell.execute_reply.started": "2024-05-02T07:25:53.820725Z",
     "shell.execute_reply": "2024-05-02T07:25:53.896588Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:45.721729500Z",
     "start_time": "2024-05-02T11:09:45.586017600Z"
    }
   },
   "execution_count": 141,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in range(len(word_ls)):\n",
    "    print(f'The top ten similar words to {word_ls[i]} are: {\",\".join(top_similar_words[i])}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:53.898518Z",
     "iopub.execute_input": "2024-05-02T07:25:53.898847Z",
     "iopub.status.idle": "2024-05-02T07:25:53.904072Z",
     "shell.execute_reply.started": "2024-05-02T07:25:53.898818Z",
     "shell.execute_reply": "2024-05-02T07:25:53.903124Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:45.761854900Z",
     "start_time": "2024-05-02T11:09:45.596166400Z"
    }
   },
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top ten similar words to me are: him,us,them,thee,herself,himself,myself,yourself,her,ourselves\n",
      "The top ten similar words to white are: black,red,golden,gray,soft,big,green,heavy,yellow,beautiful\n",
      "The top ten similar words to man are: woman,gentleman,lady,soldier,girl,child,lad,person,creature,fellow\n",
      "The top ten similar words to have are: ve,having,has,had,hast,consider,choose,take,beat,find\n",
      "The top ten similar words to be are: remain,stand,serve,being,find,exist,enter,get,prove,grow\n",
      "The top ten similar words to child are: soldier,dog,woman,man,priest,gentleman,lady,lad,boy,porter\n",
      "The top ten similar words to yes are: ,,sir,?,—,!,),suppose,pray,remember,.\n",
      "The top ten similar words to what are: why,whether,how,whatever,where,whom,which,that,because,yours\n",
      "The top ten similar words to cold are: calm,hot,weak,sad,quiet,warm,beautiful,strong,merry,gentle\n",
      "The top ten similar words to wet are: beautiful,firm,broken,frightened,cold,severe,familiar,mingled,weak,dark\n",
      "The top ten similar words to ran are: went,rode,flew,rushed,drove,sprang,jumped,galloped,stepped,slipped\n",
      "The top ten similar words to convinced are: evident,aware,observed,provided,discovered,conscious,telling,saying,satisfied,believed\n",
      "The top ten similar words to scare are: sovereign,surprise,sorrow,terror,trembling,existence,curiosity,books,rage,horror\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualising embeddings\n",
    "\n",
    "https://projector.tensorflow.org/"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "vocab_ls = vocab.lookup_tokens(range(VOCAB_SIZE))\n",
    "\n",
    "embeddings_df = pd.DataFrame(normalized_embeddings.cpu())\n",
    "\n",
    "# Convert the vocabulary to a DataFrame\n",
    "vocab_df = pd.DataFrame(vocab_ls)\n",
    "\n",
    "embeddings_path = 'embedding/'\n",
    "\n",
    "# Save the embeddings as a TSV file\n",
    "embeddings_df.to_csv(embeddings_path + 'embeddings.tsv', sep='\\t', header=False, index=False)\n",
    "\n",
    "# Save the vocabulary as a TSV file\n",
    "vocab_df.to_csv(embeddings_path + '/csv_vocab.tsv', sep='\\t', header=False, index=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:53.905244Z",
     "iopub.execute_input": "2024-05-02T07:25:53.905517Z",
     "iopub.status.idle": "2024-05-02T07:25:54.025962Z",
     "shell.execute_reply.started": "2024-05-02T07:25:53.905494Z",
     "shell.execute_reply": "2024-05-02T07:25:54.025215Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:45.838784500Z",
     "start_time": "2024-05-02T11:09:45.604483100Z"
    }
   },
   "execution_count": 143,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(vocab_df.head())\n",
    "print()\n",
    "print(embeddings_df.head())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.027098Z",
     "iopub.execute_input": "2024-05-02T07:25:54.027397Z",
     "iopub.status.idle": "2024-05-02T07:25:54.044289Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.027372Z",
     "shell.execute_reply": "2024-05-02T07:25:54.043343Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:45.861936600Z",
     "start_time": "2024-05-02T11:09:45.692274800Z"
    }
   },
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0\n",
      "0  <unk>\n",
      "1      ,\n",
      "2    the\n",
      "3      .\n",
      "4    and\n",
      "\n",
      "         0         1         2         3         4         5         6   \\\n",
      "0  0.073012 -0.206832 -0.252393 -0.019664  0.244478 -0.075594  0.146849   \n",
      "1  0.141393 -0.005656  0.018705 -0.151012  0.106441  0.091766 -0.069533   \n",
      "2 -0.375181 -0.211718 -0.171357  0.222586  0.092827 -0.138984 -0.255654   \n",
      "3 -0.100052  0.096181  0.290298 -0.218915  0.021255  0.127657 -0.137882   \n",
      "4 -0.137398  0.127038  0.074155 -0.435377 -0.215810 -0.112719  0.196020   \n",
      "\n",
      "         7         8         9   ...        22        23        24        25  \\\n",
      "0 -0.275250  0.349527 -0.084009  ... -0.127031 -0.174418 -0.077118  0.280887   \n",
      "1 -0.034630 -0.132091  0.175377  ... -0.320935  0.253002  0.021195 -0.119807   \n",
      "2  0.152078  0.029543 -0.096057  ...  0.023932  0.279010  0.030458  0.045584   \n",
      "3  0.084834 -0.583147  0.043893  ... -0.272811  0.326768 -0.145677  0.001816   \n",
      "4 -0.071211 -0.500548 -0.032921  ...  0.032088  0.027607 -0.315452 -0.107383   \n",
      "\n",
      "         26        27        28        29        30        31  \n",
      "0  0.154508  0.228686  0.179142  0.098192  0.169849 -0.035011  \n",
      "1 -0.303680  0.205676  0.125174 -0.195732  0.077016  0.101128  \n",
      "2  0.039780  0.032052  0.128488  0.030198 -0.224861  0.237319  \n",
      "3 -0.263962  0.219677  0.024584  0.161078  0.134764  0.034856  \n",
      "4  0.197563  0.021284 -0.095941 -0.010936 -0.056496  0.294961  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conjugating <em>be</em> and <em>have</em>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Creating the dataset for be/have conjugation,\n",
    "# adjusting the create dataset function from earlier"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.045478Z",
     "iopub.execute_input": "2024-05-02T07:25:54.045756Z",
     "iopub.status.idle": "2024-05-02T07:25:54.050263Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.045732Z",
     "shell.execute_reply": "2024-05-02T07:25:54.049242Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:45.866632500Z",
     "start_time": "2024-05-02T11:09:45.707570400Z"
    }
   },
   "execution_count": 145,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_conjugation_dataset(text, vocab, conjugation_words, context_size=CONTEXT_SIZE):\n",
    "    \"\"\"\n",
    "    Create a PyTorch dataset of context/target pairs from a text\n",
    "    \"\"\"\n",
    "\n",
    "    # Define punctuation symbols\n",
    "    string_punctuations = string.punctuation\n",
    "    punctuations = [vocab[p] for p in string_punctuations\n",
    "               if vocab[p] != 0]\n",
    "    \n",
    "    # Transform the text into a list of integers from vocabulary\n",
    "    txt = [vocab[w] for w in text]\n",
    "    \n",
    "    n_text = len(txt)\n",
    "\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    for i in range(n_text - context_size*2):\n",
    "        # Word directly after the start of context is the target.\n",
    "        target = txt[i + context_size]\n",
    "        word = vocab.lookup_token(target)\n",
    "        # Skip targets that are unknown:\n",
    "        if word != '<unk>' and target not in punctuations:\n",
    "            if word in conjugation_words:\n",
    "                # Context before target\n",
    "                context_before = txt[i:i + context_size]\n",
    "\n",
    "                # Context after the target\n",
    "                context_behind = txt[i + context_size + 1: i + context_size*2 + 1]\n",
    "\n",
    "                # Add context\n",
    "                contexts.append(torch.tensor(context_before + context_behind))\n",
    "                \n",
    "                # Add mapped target\n",
    "                targets.append(conjugation_words.index(word))\n",
    "\n",
    "    # Convert contexts and targets into PyTorch tensors and stack for dataset formation.\n",
    "    contexts = torch.stack(contexts)\n",
    "    targets = torch.tensor(targets)\n",
    "    \n",
    "    # Create a PyTorch dataset from these context/target pairs\n",
    "    return TensorDataset(contexts, targets)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.051500Z",
     "iopub.execute_input": "2024-05-02T07:25:54.051787Z",
     "iopub.status.idle": "2024-05-02T07:25:54.062316Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.051756Z",
     "shell.execute_reply": "2024-05-02T07:25:54.061408Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.022242800Z",
     "start_time": "2024-05-02T11:09:45.714996300Z"
    }
   },
   "execution_count": 146,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_conjugation(words, vocab, fname):\n",
    "    \"\"\"\n",
    "    Load dataset if already generated, otherwise, create it and save it\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset_path = 'dataset/'\n",
    "    \n",
    "    \n",
    "    conjugations = ['be', 'am', 'are', 'is', 'was', 'were', 'been',\n",
    "                    'being', 'have', 'has', 'had', 'having']\n",
    "    \n",
    "    # If already generated\n",
    "    if os.path.isfile(dataset_path + fname):\n",
    "        dataset = torch.load(dataset_path + fname)\n",
    "    else:\n",
    "        # Create context / target dataset based on the list of strings\n",
    "        dataset = create_conjugation_dataset(words, vocab, conjugations)\n",
    "        torch.save(dataset, dataset_path + fname)\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "c_train = load_conjugation(words_train, vocab, \"c_train.pt\")\n",
    "c_val = load_conjugation(words_val, vocab, \"c_val.pt\")\n",
    "c_test = load_conjugation(words_test, vocab, \"c_test.pt\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.070949Z",
     "iopub.execute_input": "2024-05-02T07:25:54.071297Z",
     "iopub.status.idle": "2024-05-02T07:25:54.082134Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.071271Z",
     "shell.execute_reply": "2024-05-02T07:25:54.081287Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.059978100Z",
     "start_time": "2024-05-02T11:09:45.725444900Z"
    }
   },
   "execution_count": 147,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"The training data has {len(c_train)} entries.\")\n",
    "print(f\"The validation data has {len(c_val)} entries.\")\n",
    "print(f\"The test data has {len(c_test)} entries.\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.083181Z",
     "iopub.execute_input": "2024-05-02T07:25:54.083472Z",
     "iopub.status.idle": "2024-05-02T07:25:54.093412Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.083443Z",
     "shell.execute_reply": "2024-05-02T07:25:54.092553Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.102156200Z",
     "start_time": "2024-05-02T11:09:45.742123700Z"
    }
   },
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data has 124031 entries.\n",
      "The validation data has 2590 entries.\n",
      "The test data has 4765 entries.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Labels and distribution\n",
    "torch.unique(c_train.tensors[1], return_counts=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.094523Z",
     "iopub.execute_input": "2024-05-02T07:25:54.094784Z",
     "iopub.status.idle": "2024-05-02T07:25:54.116461Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.094761Z",
     "shell.execute_reply": "2024-05-02T07:25:54.115583Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.139287800Z",
     "start_time": "2024-05-02T11:09:45.748738800Z"
    }
   },
   "execution_count": 149,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]),\n tensor([13255,  2169,  8800, 19965, 29046,  8219,  5446,  1678, 10205,  3817,\n         20159,  1272]))"
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models, positional encoding and attention"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Positional encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_dim, max_len=128):\n",
    "        super().__init__()\n",
    "    \n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, emb_dim, 2) * -(math.log(10000.0) / emb_dim))\n",
    "        \n",
    "        pe = torch.zeros(max_len, 1, emb_dim)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return x"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.117614Z",
     "iopub.execute_input": "2024-05-02T07:25:54.117894Z",
     "iopub.status.idle": "2024-05-02T07:25:54.125099Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.117871Z",
     "shell.execute_reply": "2024-05-02T07:25:54.124176Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.186578200Z",
     "start_time": "2024-05-02T11:09:45.764075Z"
    }
   },
   "execution_count": 150,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Inspired by: https://spotintelligence.com/2023/01/31/self-attention/\n",
    "class SingleHeadAttention(nn.Module):\n",
    "    def __init__(self, p, emb_dim):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.Q_W = nn.Linear(emb_dim, p)\n",
    "        self.K_W = nn.Linear(emb_dim, p)\n",
    "        self.V_W = nn.Linear(emb_dim, p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        Q = self.Q_W(x)\n",
    "        K = self.K_W(x)\n",
    "        V = self.V_W(x)\n",
    "        \n",
    "        a_scores = torch.bmm(Q, K.transpose(1, 2)) / torch.sqrt(torch.tensor(self.p))\n",
    "        a_weights = F.softmax(a_scores, dim=2)\n",
    "        return torch.bmm(a_weights, V)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.126357Z",
     "iopub.execute_input": "2024-05-02T07:25:54.126990Z",
     "iopub.status.idle": "2024-05-02T07:25:54.136557Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.126957Z",
     "shell.execute_reply": "2024-05-02T07:25:54.135651Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.239179900Z",
     "start_time": "2024-05-02T11:09:45.780056200Z"
    }
   },
   "execution_count": 151,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_dim, n_head):\n",
    "        super().__init__()\n",
    "        self.p = emb_dim // n_head\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        self.heads = nn.ModuleList([SingleHeadAttention(self.p, emb_dim)\n",
    "                                   for h in range(n_head)])\n",
    "        self.W_O = nn.Linear(self.p*n_head, emb_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        head_outputs = [head(x) for head in self.heads]\n",
    "\n",
    "        # Concatenate the inputs\n",
    "        output = torch.cat(head_outputs, dim=-1)\n",
    "        \n",
    "        return self.W_O(output)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.137933Z",
     "iopub.execute_input": "2024-05-02T07:25:54.138238Z",
     "iopub.status.idle": "2024-05-02T07:25:54.151186Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.138215Z",
     "shell.execute_reply": "2024-05-02T07:25:54.150264Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.245374600Z",
     "start_time": "2024-05-02T11:09:45.787231700Z"
    }
   },
   "execution_count": 152,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, embedding, max_len=4, output_size=12):\n",
    "        super().__init__()\n",
    "        \n",
    "        emb_dim = embedding.weight.shape[1]\n",
    "        \n",
    "        # Freeze the embedding\n",
    "        self.embedding = embedding\n",
    "        self.embedding.weight.requires_grad=False\n",
    "        \n",
    "        self.fc1 = nn.Linear(emb_dim*max_len, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.152351Z",
     "iopub.execute_input": "2024-05-02T07:25:54.152758Z",
     "iopub.status.idle": "2024-05-02T07:25:54.161045Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.152727Z",
     "shell.execute_reply": "2024-05-02T07:25:54.160124Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.276090Z",
     "start_time": "2024-05-02T11:09:45.795108500Z"
    }
   },
   "execution_count": 153,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class AttentionMLP(nn.Module):\n",
    "    def __init__(self, embedding, output_size=12, attention_heads=6, \n",
    "                 max_len=4, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        # max_len is implicit\n",
    "        # takes input: [batch_size, max_len, emb_dim]\n",
    "        emb_dim = embedding.weight.shape[1]\n",
    "        self.embedding = embedding\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.attention = MultiHeadAttention(emb_dim, attention_heads) \n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(emb_dim)\n",
    "        \n",
    "        self.fc1 = nn.Linear(emb_dim, 128)\n",
    "        self.batchnorm128 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.batchnorm64 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.attention(x)\n",
    "        x = torch.mean(x, dim=1) # pooling over sequence length removes max_len dimension\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = self.batchnorm128(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.batchnorm64(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return self.fc3(x)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.162184Z",
     "iopub.execute_input": "2024-05-02T07:25:54.162525Z",
     "iopub.status.idle": "2024-05-02T07:25:54.172727Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.162494Z",
     "shell.execute_reply": "2024-05-02T07:25:54.171821Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.282665600Z",
     "start_time": "2024-05-02T11:09:45.805202500Z"
    }
   },
   "execution_count": 154,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, embedding, hidden_size=16, num_layers = 2, output_size=12, \n",
    "                 dropout_rate=0, max_len=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        emb_dim = embedding.weight.shape[1]\n",
    "        self.embedding = embedding\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Creating num_layers RNN layers with size hidden_size\n",
    "        self.rnn = nn.RNN(emb_dim, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        st, lt = self.rnn(x)\n",
    "        x = self.dropout(lt[-1])\n",
    "        x = F.relu(x)\n",
    "        return self.fc(x)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.173746Z",
     "iopub.execute_input": "2024-05-02T07:25:54.174018Z",
     "iopub.status.idle": "2024-05-02T07:25:54.187637Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.173996Z",
     "shell.execute_reply": "2024-05-02T07:25:54.186684Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.312729400Z",
     "start_time": "2024-05-02T11:09:45.813908300Z"
    }
   },
   "execution_count": 155,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embedding = selected_cbow.embedding"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.189036Z",
     "iopub.execute_input": "2024-05-02T07:25:54.189397Z",
     "iopub.status.idle": "2024-05-02T07:25:54.198386Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.189362Z",
     "shell.execute_reply": "2024-05-02T07:25:54.197417Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.343299100Z",
     "start_time": "2024-05-02T11:09:45.819941600Z"
    }
   },
   "execution_count": 156,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.unique(c_train.tensors[1])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.199673Z",
     "iopub.execute_input": "2024-05-02T07:25:54.200400Z",
     "iopub.status.idle": "2024-05-02T07:25:54.215426Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.200356Z",
     "shell.execute_reply": "2024-05-02T07:25:54.214316Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.396170500Z",
     "start_time": "2024-05-02T11:09:45.825766600Z"
    }
   },
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def run_conjugations(models, model_names, learning_rates, num_epochs):\n",
    "    total_losses = []\n",
    "    model_path = 'models/classification/'\n",
    "    train_loader = DataLoader(c_train, batch_size=64)\n",
    "    val_loader = DataLoader(c_val, batch_size=64)\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        for lr in learning_rates:\n",
    "            if not os.path.isfile(model_path + model_names[i] +\n",
    "                                f\"lr_{lr}_e{num_epochs}\" + '.pt'):\n",
    "                training = copy.deepcopy(model) # makes sure we create a new instance for each lr\n",
    "                optim = torch.optim.Adam(training.parameters(), lr=lr)\n",
    "                loss_fn = nn.CrossEntropyLoss()\n",
    "                print(f'Currently training model: {model_names[i]} with learning rate = {lr}.')\n",
    "                losses = train(num_epochs, optim, training, loss_fn, train_loader, val_loader)\n",
    "                total_losses.append(losses)\n",
    "\n",
    "                torch.save(training, model_path + model_names[i] +\n",
    "                            f\"lr_{lr}_e{num_epochs}\" + '.pt')\n",
    "                \n",
    "    return total_losses"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.216838Z",
     "iopub.execute_input": "2024-05-02T07:25:54.217208Z",
     "iopub.status.idle": "2024-05-02T07:25:54.225588Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.217182Z",
     "shell.execute_reply": "2024-05-02T07:25:54.224773Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.454608500Z",
     "start_time": "2024-05-02T11:09:45.839910600Z"
    }
   },
   "execution_count": 158,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(seed)\n",
    "simple_mlp = SimpleMLP(embedding).to(device)\n",
    "attention_mlp = AttentionMLP(embedding).to(device)\n",
    "attention_mlp_no_dropout = AttentionMLP(embedding, dropout_rate=0).to(device)\n",
    "rnn = RNN(embedding).to(device)\n",
    "bigger_rnn = RNN(embedding, hidden_size=24, num_layers=4, dropout_rate=0.2).to(device)\n",
    "\n",
    "models = [simple_mlp, attention_mlp, attention_mlp_no_dropout, rnn, bigger_rnn]\n",
    "names = ['SimpleMLP', 'AttentionMLP', 'AttentionMLPNoDropout', 'RNN', 'BiggerRNN']\n",
    "\n",
    "losses = run_conjugations(models, names, [0.001, 0.005, 0.01], 30)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.226687Z",
     "iopub.execute_input": "2024-05-02T07:25:54.226974Z",
     "iopub.status.idle": "2024-05-02T07:25:54.344447Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.226950Z",
     "shell.execute_reply": "2024-05-02T07:25:54.343624Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.524331200Z",
     "start_time": "2024-05-02T11:09:45.847415100Z"
    }
   },
   "execution_count": 159,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Run all models with lr = 0.001 for 50 epochs to see if they improve,\n",
    "# as losses didn't seem to stabilise yet for some of these models"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.345711Z",
     "iopub.execute_input": "2024-05-02T07:25:54.346081Z",
     "iopub.status.idle": "2024-05-02T07:25:54.350299Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.346032Z",
     "shell.execute_reply": "2024-05-02T07:25:54.349336Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.530521700Z",
     "start_time": "2024-05-02T11:09:45.874510500Z"
    }
   },
   "execution_count": 160,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def run_conjugations2(models, model_names):\n",
    "    total_losses = []\n",
    "    model_path = 'models/classification/'\n",
    "    train_loader = DataLoader(c_train, batch_size=64)\n",
    "    val_loader = DataLoader(c_val, batch_size=64)\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        if not os.path.isfile(model_path + model_names[i] +\n",
    "                             \"lr_0.001_e50\" + '.pt'):\n",
    "            optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            print(f'Currently training model: {model_names[i]} with learning rate = 0.001.')\n",
    "            losses = train(50, optim, model, loss_fn, train_loader, val_loader)\n",
    "            total_losses.append(losses)\n",
    "\n",
    "            torch.save(model, model_path + model_names[i] +\n",
    "                      \"lr_0.001_e50\" + '.pt')\n",
    "                \n",
    "    return total_losses"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.351416Z",
     "iopub.execute_input": "2024-05-02T07:25:54.351678Z",
     "iopub.status.idle": "2024-05-02T07:25:54.360548Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.351648Z",
     "shell.execute_reply": "2024-05-02T07:25:54.359761Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.536868100Z",
     "start_time": "2024-05-02T11:09:45.881593200Z"
    }
   },
   "execution_count": 161,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "simple_mlp = SimpleMLP(embedding).to(device)\n",
    "attention_mlp = AttentionMLP(embedding).to(device)\n",
    "attention_mlp_no_dropout = AttentionMLP(embedding, dropout_rate=0).to(device)\n",
    "rnn = RNN(embedding).to(device)\n",
    "bigger_rnn = RNN(embedding, hidden_size=24, num_layers=4, dropout_rate=0.2).to(device)\n",
    "\n",
    "models = [simple_mlp, attention_mlp, attention_mlp_no_dropout, rnn, bigger_rnn]\n",
    "names = ['SimpleMLP', 'AttentionMLP', 'AttentionMLPNoDropout', 'RNN', 'BiggerRNN']\n",
    "\n",
    "losses = run_conjugations(models, names, [0.001], 50)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.361500Z",
     "iopub.execute_input": "2024-05-02T07:25:54.361765Z",
     "iopub.status.idle": "2024-05-02T07:25:54.390798Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.361734Z",
     "shell.execute_reply": "2024-05-02T07:25:54.390006Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.564994400Z",
     "start_time": "2024-05-02T11:09:45.889353Z"
    }
   },
   "execution_count": 162,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "classification_path = 'models/classification/'\n",
    "models = []\n",
    "model_names = []\n",
    "for file in os.listdir(classification_path):\n",
    "    model = torch.load(classification_path + file, map_location=device)\n",
    "    models.append(model)\n",
    "    model_names.append(file[:-3])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.391807Z",
     "iopub.execute_input": "2024-05-02T07:25:54.392093Z",
     "iopub.status.idle": "2024-05-02T07:25:54.506028Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.392046Z",
     "shell.execute_reply": "2024-05-02T07:25:54.505007Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.708743800Z",
     "start_time": "2024-05-02T11:09:45.909406300Z"
    }
   },
   "execution_count": 163,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print('All models to test:\\n')\n",
    "for name in model_names:\n",
    "    print(name)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.507494Z",
     "iopub.execute_input": "2024-05-02T07:25:54.507786Z",
     "iopub.status.idle": "2024-05-02T07:25:54.512452Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.507761Z",
     "shell.execute_reply": "2024-05-02T07:25:54.511605Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:46.756890300Z",
     "start_time": "2024-05-02T11:09:46.019662200Z"
    }
   },
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models to test:\n",
      "\n",
      "AttentionMLPlr_0.001_e30\n",
      "AttentionMLPlr_0.001_e50\n",
      "AttentionMLPlr_0.005_e30\n",
      "AttentionMLPlr_0.01_e30\n",
      "AttentionMLPNoDropoutlr_0.001_e30\n",
      "AttentionMLPNoDropoutlr_0.001_e50\n",
      "AttentionMLPNoDropoutlr_0.005_e30\n",
      "AttentionMLPNoDropoutlr_0.01_e30\n",
      "BiggerRNNlr_0.001_e30\n",
      "BiggerRNNlr_0.001_e50\n",
      "BiggerRNNlr_0.005_e30\n",
      "BiggerRNNlr_0.01_e30\n",
      "RNNlr_0.001_e30\n",
      "RNNlr_0.001_e50\n",
      "RNNlr_0.005_e30\n",
      "RNNlr_0.01_e30\n",
      "SimpleMLPlr_0.001_e30\n",
      "SimpleMLPlr_0.001_e50\n",
      "SimpleMLPlr_0.005_e30\n",
      "SimpleMLPlr_0.01_e30\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(seed)\n",
    "def evaluate_and_select_conjugator(models, model_names, val_loader):\n",
    "    accs = []\n",
    "\n",
    "    for model in models:\n",
    "        acc = compute_accuracy(model, val_loader, device=device)\n",
    "        accs.append(acc)\n",
    "    \n",
    "    model_idx = accs.index(max(accs))\n",
    "    print(f'Max accuracy: {accs[model_idx]:.3f}, selected model: model: {model_idx + 1}: {model_names[model_idx]}', end='\\n')\n",
    "    \n",
    "    all_accs = \"\\n\\n\".join([f\"{model_name}: {acc:.3f}\" for model_name, acc in zip(model_names, accs)])\n",
    "    print('All accuracies:')\n",
    "    print(all_accs)\n",
    "    return models[model_idx]\n",
    "\n",
    "\n",
    "c_val_loader = DataLoader(c_val, batch_size=64)\n",
    "selected_conjugator = evaluate_and_select_conjugator(models, model_names, c_val_loader)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:54.513632Z",
     "iopub.execute_input": "2024-05-02T07:25:54.513897Z",
     "iopub.status.idle": "2024-05-02T07:25:56.014783Z",
     "shell.execute_reply.started": "2024-05-02T07:25:54.513874Z",
     "shell.execute_reply": "2024-05-02T07:25:56.013796Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:48.048276500Z",
     "start_time": "2024-05-02T11:09:46.025433300Z"
    }
   },
   "execution_count": 165,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy: 0.446, selected model: model: 10: BiggerRNNlr_0.001_e50\n",
      "All accuracies:\n",
      "AttentionMLPlr_0.001_e30: 0.382\n",
      "\n",
      "AttentionMLPlr_0.001_e50: 0.415\n",
      "\n",
      "AttentionMLPlr_0.005_e30: 0.374\n",
      "\n",
      "AttentionMLPlr_0.01_e30: 0.373\n",
      "\n",
      "AttentionMLPNoDropoutlr_0.001_e30: 0.375\n",
      "\n",
      "AttentionMLPNoDropoutlr_0.001_e50: 0.375\n",
      "\n",
      "AttentionMLPNoDropoutlr_0.005_e30: 0.375\n",
      "\n",
      "AttentionMLPNoDropoutlr_0.01_e30: 0.364\n",
      "\n",
      "BiggerRNNlr_0.001_e30: 0.437\n",
      "\n",
      "BiggerRNNlr_0.001_e50: 0.446\n",
      "\n",
      "BiggerRNNlr_0.005_e30: 0.383\n",
      "\n",
      "BiggerRNNlr_0.01_e30: 0.308\n",
      "\n",
      "RNNlr_0.001_e30: 0.442\n",
      "\n",
      "RNNlr_0.001_e50: 0.440\n",
      "\n",
      "RNNlr_0.005_e30: 0.390\n",
      "\n",
      "RNNlr_0.01_e30: 0.376\n",
      "\n",
      "SimpleMLPlr_0.001_e30: 0.438\n",
      "\n",
      "SimpleMLPlr_0.001_e50: 0.443\n",
      "\n",
      "SimpleMLPlr_0.005_e30: 0.407\n",
      "\n",
      "SimpleMLPlr_0.01_e30: 0.405\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Final results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "selected_conjugator"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:56.015927Z",
     "iopub.execute_input": "2024-05-02T07:25:56.016243Z",
     "iopub.status.idle": "2024-05-02T07:25:56.022448Z",
     "shell.execute_reply.started": "2024-05-02T07:25:56.016217Z",
     "shell.execute_reply": "2024-05-02T07:25:56.021448Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:48.078744Z",
     "start_time": "2024-05-02T11:09:48.041103Z"
    }
   },
   "execution_count": 166,
   "outputs": [
    {
     "data": {
      "text/plain": "RNN(\n  (embedding): Embedding(1880, 32)\n  (dropout): Dropout(p=0.2, inplace=False)\n  (rnn): RNN(32, 24, num_layers=4, batch_first=True)\n  (fc): Linear(in_features=24, out_features=12, bias=True)\n)"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(seed)\n",
    "c_train_loader = DataLoader(c_train, batch_size=64)\n",
    "c_val_loader = DataLoader(c_val, batch_size=64)\n",
    "c_test_loader = DataLoader(c_test, batch_size=64)\n",
    "\n",
    "train_acc = compute_accuracy(selected_conjugator, c_train_loader, device=device)\n",
    "val_acc = compute_accuracy(selected_conjugator, c_val_loader, device=device)\n",
    "test_acc = compute_accuracy(selected_conjugator, c_test_loader, device=device)\n",
    "\n",
    "print(f'Final model accuracy on train data: {train_acc:.3f}')\n",
    "print(f'Final model accuracy on val data: {val_acc:.3f}')\n",
    "print(f'Final model accuracy on test data: {test_acc:.3f}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:56.023654Z",
     "iopub.execute_input": "2024-05-02T07:25:56.023936Z",
     "iopub.status.idle": "2024-05-02T07:25:58.287349Z",
     "shell.execute_reply.started": "2024-05-02T07:25:56.023913Z",
     "shell.execute_reply": "2024-05-02T07:25:58.286374Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:52.535169900Z",
     "start_time": "2024-05-02T11:09:48.049366600Z"
    }
   },
   "execution_count": 167,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model accuracy on train data: 0.482\n",
      "Final model accuracy on val data: 0.446\n",
      "Final model accuracy on test data: 0.407\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def show_samples(contexts, preds, n):\n",
    "    selected_contexts = contexts[:n]\n",
    "    selected_preds = preds[:n]\n",
    "    mapping = ['be', 'am', 'are', 'is', 'was', 'were', 'been',\n",
    "                    'being', 'have', 'has', 'had', 'having']\n",
    "    \n",
    "    for idx in range(len(selected_contexts)):\n",
    "        context_before = selected_contexts[idx][:2].tolist()\n",
    "        context_after = selected_contexts[idx][2:].tolist()\n",
    "        prediction = mapping[selected_preds[idx]]\n",
    "        \n",
    "        print(f'Showing sample: {idx + 1}')\n",
    "        print(f'{\" \".join(vocab.lookup_tokens(context_before))} *{prediction}* {\" \".join(vocab.lookup_tokens(context_after))}')\n",
    "        print()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:58.288571Z",
     "iopub.execute_input": "2024-05-02T07:25:58.288880Z",
     "iopub.status.idle": "2024-05-02T07:25:58.295919Z",
     "shell.execute_reply.started": "2024-05-02T07:25:58.288854Z",
     "shell.execute_reply": "2024-05-02T07:25:58.294917Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:52.608670600Z",
     "start_time": "2024-05-02T11:09:52.535169900Z"
    }
   },
   "execution_count": 168,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "all_val_logits = selected_conjugator(c_val[:][0].to(device))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:58.297632Z",
     "iopub.execute_input": "2024-05-02T07:25:58.298011Z",
     "iopub.status.idle": "2024-05-02T07:25:58.312400Z",
     "shell.execute_reply.started": "2024-05-02T07:25:58.297978Z",
     "shell.execute_reply": "2024-05-02T07:25:58.311531Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:52.718132400Z",
     "start_time": "2024-05-02T11:09:52.540670300Z"
    }
   },
   "execution_count": 169,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "predictions = F.softmax(all_val_logits, dim=1)\n",
    "predicted_conjugations = torch.argmax(predictions, dim=1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:58.313665Z",
     "iopub.execute_input": "2024-05-02T07:25:58.314035Z",
     "iopub.status.idle": "2024-05-02T07:25:58.335521Z",
     "shell.execute_reply.started": "2024-05-02T07:25:58.314000Z",
     "shell.execute_reply": "2024-05-02T07:25:58.334700Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:52.762211300Z",
     "start_time": "2024-05-02T11:09:52.565075700Z"
    }
   },
   "execution_count": 170,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Sample incorrect predictions\n",
    "all_incorrect_preds = predicted_conjugations[predicted_conjugations != c_val[:][1].to(device)]\n",
    "all_incorrect_contexts = c_val[:][0].to(device)[predicted_conjugations != c_val[:][1].to(device)]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:58.344128Z",
     "iopub.execute_input": "2024-05-02T07:25:58.344792Z",
     "iopub.status.idle": "2024-05-02T07:25:58.353848Z",
     "shell.execute_reply.started": "2024-05-02T07:25:58.344757Z",
     "shell.execute_reply": "2024-05-02T07:25:58.353170Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:52.791656300Z",
     "start_time": "2024-05-02T11:09:52.575594400Z"
    }
   },
   "execution_count": 171,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Sample correct predictions\n",
    "all_correct_preds = predicted_conjugations[predicted_conjugations == c_val[:][1].to(device)]\n",
    "all_correct_contexts = c_val[:][0].to(device)[predicted_conjugations == c_val[:][1].to(device)]\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:58.355093Z",
     "iopub.execute_input": "2024-05-02T07:25:58.355384Z",
     "iopub.status.idle": "2024-05-02T07:25:58.364774Z",
     "shell.execute_reply.started": "2024-05-02T07:25:58.355359Z",
     "shell.execute_reply": "2024-05-02T07:25:58.363688Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:52.796386600Z",
     "start_time": "2024-05-02T11:09:52.583695800Z"
    }
   },
   "execution_count": 172,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print('Ten incorrect samples:')\n",
    "show_samples(all_incorrect_contexts, all_incorrect_preds, 10)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:58.365846Z",
     "iopub.execute_input": "2024-05-02T07:25:58.366143Z",
     "iopub.status.idle": "2024-05-02T07:25:58.375577Z",
     "shell.execute_reply.started": "2024-05-02T07:25:58.366120Z",
     "shell.execute_reply": "2024-05-02T07:25:58.374516Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:52.814423100Z",
     "start_time": "2024-05-02T11:09:52.591416500Z"
    }
   },
   "execution_count": 173,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten incorrect samples:\n",
      "Showing sample: 1\n",
      ". ( *is* a <unk>\n",
      "\n",
      "Showing sample: 2\n",
      "army . *are* <unk> my\n",
      "\n",
      "Showing sample: 3\n",
      ", i *am* <unk> attached\n",
      "\n",
      "Showing sample: 4\n",
      "the regiment *is* <unk> in\n",
      "\n",
      "Showing sample: 5\n",
      "<unk> war *is* broken out\n",
      "\n",
      "Showing sample: 6\n",
      "my <unk> *is* advanced through\n",
      "\n",
      "Showing sample: 7\n",
      "officers who *are* in the\n",
      "\n",
      "Showing sample: 8\n",
      "me it *is* nothing but\n",
      "\n",
      "Showing sample: 9\n",
      ". i *am* removed from\n",
      "\n",
      "Showing sample: 10\n",
      "there i *been* struck on\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print('Ten correct samples:')\n",
    "show_samples(all_correct_contexts, all_correct_preds, 10)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:58.376717Z",
     "iopub.execute_input": "2024-05-02T07:25:58.377012Z",
     "iopub.status.idle": "2024-05-02T07:25:58.385439Z",
     "shell.execute_reply.started": "2024-05-02T07:25:58.376980Z",
     "shell.execute_reply": "2024-05-02T07:25:58.384568Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:52.817689200Z",
     "start_time": "2024-05-02T11:09:52.599371Z"
    }
   },
   "execution_count": 174,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten correct samples:\n",
      "Showing sample: 1\n",
      ", and *was* already deep\n",
      "\n",
      "Showing sample: 2\n",
      "i should *have* fallen into\n",
      "\n",
      "Showing sample: 3\n",
      "it not *been* for the\n",
      "\n",
      "Showing sample: 4\n",
      "as to *be* able to\n",
      "\n",
      "Showing sample: 5\n",
      "day should *be* lost in\n",
      "\n",
      "Showing sample: 6\n",
      "man to *be* . under\n",
      "\n",
      "Showing sample: 7\n",
      "the <unk> *are* <unk> <unk>\n",
      "\n",
      "Showing sample: 8\n",
      ", i *was* standing at\n",
      "\n",
      "Showing sample: 9\n",
      "who had *been* a <unk>\n",
      "\n",
      "Showing sample: 10\n",
      "of <unk> *is* a pleasant\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Text generation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset generation\n",
    "\n",
    "(Here we only use the context before the target word)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "g_context_size = 6"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:58.386416Z",
     "iopub.execute_input": "2024-05-02T07:25:58.386674Z",
     "iopub.status.idle": "2024-05-02T07:25:58.393616Z",
     "shell.execute_reply.started": "2024-05-02T07:25:58.386651Z",
     "shell.execute_reply": "2024-05-02T07:25:58.392743Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:52.825020900Z",
     "start_time": "2024-05-02T11:09:52.607507400Z"
    }
   },
   "execution_count": 175,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_generation_dataset(text, vocab, context_size=g_context_size):\n",
    "    \"\"\"\n",
    "    Create a PyTorch dataset of context/target pairs from a text\n",
    "    \"\"\"\n",
    "\n",
    "    # Define punctuation symbols\n",
    "    string_punctuations = string.punctuation\n",
    "    punctuations = [vocab[p] for p in string_punctuations\n",
    "               if vocab[p] != 0]\n",
    "    \n",
    "    # Transform the text into a list of integers from vocabulary\n",
    "    txt = [vocab[w] for w in text]\n",
    "    \n",
    "    n_text = len(txt)\n",
    "\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    for i in range(n_text - context_size):\n",
    "        # Word directly after the start of context is the target.\n",
    "        target = txt[i + context_size]\n",
    "        # Skip targets that are unknown:\n",
    "        if vocab.lookup_token(target) != '<unk>' and target not in punctuations:\n",
    "            # Context before target\n",
    "            context = txt[i:i + context_size]\n",
    "            \n",
    "            targets.append(target)\n",
    "            contexts.append(torch.tensor(context))\n",
    "\n",
    "    # Convert contexts and targets into PyTorch tensors and stack for dataset formation.\n",
    "    contexts = torch.stack(contexts)\n",
    "    targets = torch.tensor(targets)\n",
    "    \n",
    "    # Create a PyTorch dataset from these context/target pairs\n",
    "    return TensorDataset(contexts, targets)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:58.394828Z",
     "iopub.execute_input": "2024-05-02T07:25:58.395195Z",
     "iopub.status.idle": "2024-05-02T07:25:58.405202Z",
     "shell.execute_reply.started": "2024-05-02T07:25:58.395162Z",
     "shell.execute_reply": "2024-05-02T07:25:58.404407Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:52.843778200Z",
     "start_time": "2024-05-02T11:09:52.617264100Z"
    }
   },
   "execution_count": 176,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_generation(words, vocab, fname):\n",
    "    \"\"\"\n",
    "    Load dataset if already generated, otherwise, create it and save it\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset_path = 'dataset/'\n",
    "    \n",
    "    # If already generated\n",
    "    if os.path.isfile(dataset_path + fname):\n",
    "        dataset = torch.load(dataset_path + fname)\n",
    "    else:\n",
    "        # Create context / target dataset based on the list of strings\n",
    "        dataset = create_generation_dataset(words, vocab)\n",
    "        torch.save(dataset, dataset_path + fname)\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "g_train = load_generation(words_train, vocab, \"g_train.pt\")\n",
    "g_val = load_generation(words_val, vocab, \"g_val.pt\")\n",
    "g_test = load_generation(words_test, vocab, \"g_test.pt\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:58.406327Z",
     "iopub.execute_input": "2024-05-02T07:25:58.406750Z",
     "iopub.status.idle": "2024-05-02T07:25:58.450476Z",
     "shell.execute_reply.started": "2024-05-02T07:25:58.406719Z",
     "shell.execute_reply": "2024-05-02T07:25:58.449658Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:52.996246600Z",
     "start_time": "2024-05-02T11:09:52.626858100Z"
    }
   },
   "execution_count": 177,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(g_train.tensors[0].shape)\n",
    "print(g_train.tensors[1].shape)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:58.451522Z",
     "iopub.execute_input": "2024-05-02T07:25:58.451801Z",
     "iopub.status.idle": "2024-05-02T07:25:58.456517Z",
     "shell.execute_reply.started": "2024-05-02T07:25:58.451779Z",
     "shell.execute_reply": "2024-05-02T07:25:58.455506Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:53.002105500Z",
     "start_time": "2024-05-02T11:09:52.766798Z"
    }
   },
   "execution_count": 178,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1916840, 6])\n",
      "torch.Size([1916840])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"The training data has {len(g_train)} entries.\")\n",
    "print(f\"The validation data has {len(g_val)} entries.\")\n",
    "print(f\"The test data has {len(g_test)} entries.\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:58.457767Z",
     "iopub.execute_input": "2024-05-02T07:25:58.458062Z",
     "iopub.status.idle": "2024-05-02T07:25:58.467318Z",
     "shell.execute_reply.started": "2024-05-02T07:25:58.458035Z",
     "shell.execute_reply": "2024-05-02T07:25:58.466536Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:53.031956400Z",
     "start_time": "2024-05-02T11:09:52.773091300Z"
    }
   },
   "execution_count": 179,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data has 1916840 entries.\n",
      "The validation data has 36216 entries.\n",
      "The test data has 83641 entries.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "embedding = selected_cbow.embedding"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:58.468344Z",
     "iopub.execute_input": "2024-05-02T07:25:58.468591Z",
     "iopub.status.idle": "2024-05-02T07:25:58.481230Z",
     "shell.execute_reply.started": "2024-05-02T07:25:58.468568Z",
     "shell.execute_reply": "2024-05-02T07:25:58.480445Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:53.056514900Z",
     "start_time": "2024-05-02T11:09:52.778795700Z"
    }
   },
   "execution_count": 180,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Word generation model architecture:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class GenerationRNN(nn.Module):\n",
    "    def __init__(self, embedding, vocab_size=VOCAB_SIZE,\n",
    "                hidden_layer_size=12, n_layers=2, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        emb_dim = embedding.weight.shape[1]\n",
    "        self.embedding = embedding\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_layer_size,\n",
    "                          n_layers, dropout=dropout_rate, \n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_layer_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (hidden_state, cell_state) = self.lstm(x)\n",
    "        x = F.relu(hidden_state[-1])\n",
    "        return self.out(x)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:58.482172Z",
     "iopub.execute_input": "2024-05-02T07:25:58.482452Z",
     "iopub.status.idle": "2024-05-02T07:25:58.492465Z",
     "shell.execute_reply.started": "2024-05-02T07:25:58.482430Z",
     "shell.execute_reply": "2024-05-02T07:25:58.491149Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:09:53.076524Z",
     "start_time": "2024-05-02T11:09:52.785905600Z"
    }
   },
   "execution_count": 181,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Class frequencies for g_train and class weights"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "g_freqs = count_freqs_int(g_train[:][1], vocab)\n",
    "\n",
    "print(f'Updated frequencies for new dataset: {g_freqs[:10]}')\n",
    "\n",
    "g_freqs = torch.tensor(g_freqs, dtype=torch.float)\n",
    "\n",
    "\n",
    "total_samples = g_freqs.sum()\n",
    "\n",
    "# Calculate class weights\n",
    "g_weights = total_samples / g_freqs\n",
    "\n",
    "g_weights = torch.tensor([w if w != float('inf') else 0 for w in g_weights]).to(device)\n",
    "\n",
    "print(f'Class weights sample: {g_weights[:10]}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:25:58.493804Z",
     "iopub.execute_input": "2024-05-02T07:25:58.494205Z",
     "iopub.status.idle": "2024-05-02T07:26:26.825077Z",
     "shell.execute_reply.started": "2024-05-02T07:25:58.494178Z",
     "shell.execute_reply": "2024-05-02T07:26:26.824196Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:10:23.494747400Z",
     "start_time": "2024-05-02T11:09:52.793845200Z"
    }
   },
   "execution_count": 182,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated frequencies for new dataset: tensor([     0,      0, 151278,      0,  82288,  65661,  62763,  49230,  41477,\n",
      "         31052], dtype=torch.int32)\n",
      "Class weights sample: tensor([ 0.0000,  0.0000, 12.6710,  0.0000, 23.2943, 29.1930, 30.5409, 38.9364,\n",
      "        46.2145, 61.7300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxba\\AppData\\Local\\Temp\\ipykernel_24108\\1942707119.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  g_freqs = torch.tensor(g_freqs, dtype=torch.float)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.sum(g_weights)\n",
    "\n",
    "log_g_weights = torch.log1p(g_weights)\n",
    "print(f'Log weights sample: {log_g_weights[:10]}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:26:26.833884Z",
     "iopub.execute_input": "2024-05-02T07:26:26.834219Z",
     "iopub.status.idle": "2024-05-02T07:26:26.849473Z",
     "shell.execute_reply.started": "2024-05-02T07:26:26.834197Z",
     "shell.execute_reply": "2024-05-02T07:26:26.848551Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:10:23.531988800Z",
     "start_time": "2024-05-02T11:10:23.491185Z"
    }
   },
   "execution_count": 183,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log weights sample: tensor([0.0000, 0.0000, 2.6153, 0.0000, 3.1902, 3.4076, 3.4513, 3.6873, 3.8547,\n",
      "        4.1388])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def run_generators(models, model_names, lr, num_epochs):\n",
    "    total_losses = []\n",
    "    generator_path = 'models/generators/'\n",
    "    train_loader = DataLoader(g_train, batch_size=128)\n",
    "    val_loader = DataLoader(g_val, batch_size=128)\n",
    "    \n",
    "    for i in range(len(models)):\n",
    "        if not os.path.isfile(generator_path + model_names[i] + f'lr_{lr}_e{num_epochs}.pt'):\n",
    "            model = models[i]\n",
    "            optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "            \n",
    "            if model_names[i].endswith('W'):\n",
    "                loss_fn = nn.CrossEntropyLoss(log_g_weights)\n",
    "            else:\n",
    "                loss_fn = nn.CrossEntropyLoss()\n",
    "            \n",
    "            print(f'Currently training model: {model_names[i]} with learning_rate = {lr}')\n",
    "            losses = train(num_epochs, optim, model, loss_fn, train_loader, val_loader)\n",
    "            total_losses.append(losses)\n",
    "            torch.save(model, generator_path + model_names[i] + f'lr_{lr}_e{num_epochs}.pt')\n",
    "    \n",
    "    return total_losses"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:26:26.884481Z",
     "iopub.execute_input": "2024-05-02T07:26:26.884793Z",
     "iopub.status.idle": "2024-05-02T07:26:26.893166Z",
     "shell.execute_reply.started": "2024-05-02T07:26:26.884767Z",
     "shell.execute_reply": "2024-05-02T07:26:26.892278Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:10:23.552258700Z",
     "start_time": "2024-05-02T11:10:23.499219300Z"
    }
   },
   "execution_count": 184,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(seed)\n",
    "# First trying lr = 0.005 and 40 epochs\n",
    "generator_path = 'models/generators/'\n",
    "os.makedirs(generator_path, exist_ok=True)\n",
    "\n",
    "# Train different variations of the model -\n",
    "# essentially hyperparameter tuning\n",
    "basic_gen = GenerationRNN(embedding, dropout_rate=0)\n",
    "dropout_gen = GenerationRNN(embedding, dropout_rate=0.5)\n",
    "medium_gen = GenerationRNN(embedding, hidden_layer_size=16, n_layers=3, dropout_rate=0.3)\n",
    "deeper_gen = GenerationRNN(embedding, hidden_layer_size=24, n_layers=4)\n",
    "\n",
    "# Test all of these kinds of generators with class weights\n",
    "basic_gen_weighted = GenerationRNN(embedding, dropout_rate=0)\n",
    "dropout_gen_weighted = GenerationRNN(embedding, dropout_rate=0.5)\n",
    "medium_gen_weighted = GenerationRNN(embedding, hidden_layer_size=16, n_layers=3, dropout_rate=0.3)\n",
    "deeper_gen_weighted = GenerationRNN(embedding, n_layers=4)\n",
    "\n",
    "generation_models = [basic_gen, dropout_gen, medium_gen, deeper_gen, basic_gen_weighted,\n",
    "                     dropout_gen_weighted, medium_gen_weighted, deeper_gen_weighted]\n",
    "generation_models = [model.to(device) for model in generation_models]\n",
    "generation_names = ['Basic', 'Dropout', 'Medium', 'Deeper',\n",
    "                    'BasicW', 'DropoutW', 'MediumW', 'DeeperW']\n",
    "\n",
    "\n",
    "total_losses = run_generators(generation_models, generation_names, 0.005, 40)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:26:26.894205Z",
     "iopub.execute_input": "2024-05-02T07:26:26.894507Z",
     "iopub.status.idle": "2024-05-02T07:26:26.928276Z",
     "shell.execute_reply.started": "2024-05-02T07:26:26.894484Z",
     "shell.execute_reply": "2024-05-02T07:26:26.927463Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:10:23.710508Z",
     "start_time": "2024-05-02T11:10:23.510935200Z"
    }
   },
   "execution_count": 185,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(seed)\n",
    "# Trying learning rate 0.001 for 50 epochs, running the same model architectures\n",
    "\n",
    "# Train different variations of the model -\n",
    "# essentially hyperparameter tuning\n",
    "basic_gen = GenerationRNN(embedding, dropout_rate=0)\n",
    "dropout_gen = GenerationRNN(embedding, dropout_rate=0.5)\n",
    "medium_gen = GenerationRNN(embedding, hidden_layer_size=16, n_layers=3, dropout_rate=0.3)\n",
    "deeper_gen = GenerationRNN(embedding, hidden_layer_size=24, n_layers=4)\n",
    "\n",
    "# Test all of these kinds of generators with class weights\n",
    "basic_gen_weighted = GenerationRNN(embedding, dropout_rate=0)\n",
    "dropout_gen_weighted = GenerationRNN(embedding, dropout_rate=0.5)\n",
    "medium_gen_weighted = GenerationRNN(embedding, hidden_layer_size=16, n_layers=3, dropout_rate=0.2)\n",
    "deeper_gen_weighted = GenerationRNN(embedding, n_layers=4)\n",
    "\n",
    "generation_models = [basic_gen, dropout_gen, medium_gen, deeper_gen, basic_gen_weighted,\n",
    "                     dropout_gen_weighted, medium_gen_weighted, deeper_gen_weighted]\n",
    "generation_models = [model.to(device) for model in generation_models]\n",
    "generation_names = ['Basic', 'Dropout', 'Medium', 'Deeper',\n",
    "                    'BasicW', 'DropoutW', 'MediumW', 'DeeperW']\n",
    "\n",
    "\n",
    "total_losses = run_generators(generation_models, generation_names, 0.001, 50)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T07:26:26.929383Z",
     "iopub.execute_input": "2024-05-02T07:26:26.929670Z",
     "iopub.status.idle": "2024-05-02T10:03:12.042797Z",
     "shell.execute_reply.started": "2024-05-02T07:26:26.929645Z",
     "shell.execute_reply": "2024-05-02T10:03:12.041719Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:10:23.797234200Z",
     "start_time": "2024-05-02T11:10:23.534319300Z"
    }
   },
   "execution_count": 186,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generator_path = 'models/generators/'\n",
    "generation_models = []\n",
    "generation_names = []\n",
    "for file in os.listdir(generator_path):\n",
    "    model = torch.load(generator_path + file, map_location=device)\n",
    "    generation_models.append(model)\n",
    "    generation_names.append(file[:-3])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:05:58.256199Z",
     "iopub.execute_input": "2024-05-02T10:05:58.256894Z",
     "iopub.status.idle": "2024-05-02T10:05:58.303816Z",
     "shell.execute_reply.started": "2024-05-02T10:05:58.256861Z",
     "shell.execute_reply": "2024-05-02T10:05:58.302872Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:10:23.838302200Z",
     "start_time": "2024-05-02T11:10:23.551103800Z"
    }
   },
   "execution_count": 187,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(seed)\n",
    "def evaluate_and_select_generator(models, model_names, model_path, val_loader):\n",
    "    accs = []\n",
    "\n",
    "    for model in models:\n",
    "        acc = compute_accuracy(model, val_loader, device=device)\n",
    "        accs.append(acc)\n",
    "    \n",
    "    model_idx = accs.index(max(accs))\n",
    "    print(f'Max accuracy: {accs[model_idx]:.3f}, selected model: model: {model_idx + 1}: {model_names[model_idx]}', end='\\n')\n",
    "    \n",
    "    all_accs = \"\\n\\n\".join([f\"{model_name}: {acc:.3f}\" for model_name, acc in zip(model_names, accs)])\n",
    "    print('All accuracies:')\n",
    "    print(all_accs)\n",
    "    return models[model_idx]\n",
    "\n",
    "\n",
    "\n",
    "g_val_loader = DataLoader(g_val, batch_size=128)\n",
    "selected_generator = evaluate_and_select_generator(generation_models, generation_names, generator_path, g_val_loader)\n",
    "selected_generator = selected_generator.to(device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:06:18.137789Z",
     "iopub.execute_input": "2024-05-02T10:06:18.138695Z",
     "iopub.status.idle": "2024-05-02T10:06:27.264517Z",
     "shell.execute_reply.started": "2024-05-02T10:06:18.138658Z",
     "shell.execute_reply": "2024-05-02T10:06:27.263406Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:10:39.234141900Z",
     "start_time": "2024-05-02T11:10:23.586023100Z"
    }
   },
   "execution_count": 188,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy: 0.161, selected model: model: 1: Basiclr_0.001_e50\n",
      "All accuracies:\n",
      "Basiclr_0.001_e50: 0.161\n",
      "\n",
      "Basiclr_0.005_e40: 0.153\n",
      "\n",
      "BasicWlr_0.001_e50: 0.152\n",
      "\n",
      "BasicWlr_0.005_e40: 0.138\n",
      "\n",
      "Deeperlr_0.001_e50: 0.149\n",
      "\n",
      "Deeperlr_0.005_e40: 0.127\n",
      "\n",
      "DeeperWlr_0.001_e50: 0.116\n",
      "\n",
      "DeeperWlr_0.005_e40: 0.086\n",
      "\n",
      "Dropoutlr_0.001_e50: 0.149\n",
      "\n",
      "Dropoutlr_0.005_e40: 0.140\n",
      "\n",
      "DropoutWlr_0.001_e50: 0.139\n",
      "\n",
      "DropoutWlr_0.005_e40: 0.128\n",
      "\n",
      "Mediumlr_0.001_e50: 0.156\n",
      "\n",
      "Mediumlr_0.005_e40: 0.149\n",
      "\n",
      "MediumWlr_0.001_e50: 0.147\n",
      "\n",
      "MediumWlr_0.005_e40: 0.133\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Beam Search"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def beam_search(text_input, generator, num_predictions=4, beam_width=5):\n",
    "    words_idx = torch.tensor(vocab.lookup_indices(text_input)).to(device)\n",
    "    \n",
    "    # This list of list will store all current sequences,\n",
    "    # and track their probabilities\n",
    "    possible_sequences = [[words_idx.tolist(), 1.0]]\n",
    "    \n",
    "    for p in range(num_predictions):\n",
    "        all_candidates = []\n",
    "        \n",
    "        for seq, score in possible_sequences:\n",
    "            seq_tensor = torch.tensor([seq]).to(device)\n",
    "            \n",
    "            prediction = generator(seq_tensor)\n",
    "            probabilities = F.softmax(prediction, dim=-1)\n",
    "        \n",
    "            # Explore all possible next words\n",
    "            for w in range(VOCAB_SIZE): \n",
    "                next_score = score * probabilities[0][w].item()\n",
    "                candidate = [seq + [w], next_score]\n",
    "                all_candidates.append(candidate)\n",
    "        \n",
    "        possible_sequences = sorted(all_candidates, key=lambda tup: tup[1], reverse=True)[:beam_width]\n",
    "\n",
    "    \n",
    "    return vocab.lookup_tokens(possible_sequences[0][0])\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-05-02T10:08:34.170639Z",
     "iopub.execute_input": "2024-05-02T10:08:34.171330Z",
     "iopub.status.idle": "2024-05-02T10:08:34.181574Z",
     "shell.execute_reply.started": "2024-05-02T10:08:34.171289Z",
     "shell.execute_reply": "2024-05-02T10:08:34.180545Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:10:39.273164300Z",
     "start_time": "2024-05-02T11:10:39.229782300Z"
    }
   },
   "execution_count": 189,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performance and beam search testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(seed)\n",
    "g_train_loader = DataLoader(g_train, batch_size=128)\n",
    "g_val_loader = DataLoader(g_val, batch_size=128)\n",
    "g_test_loader = DataLoader(g_test, batch_size=128)\n",
    "\n",
    "train_acc = compute_accuracy(selected_generator, g_train_loader, device=device)\n",
    "val_acc = compute_accuracy(selected_generator, g_val_loader, device=device)\n",
    "test_acc = compute_accuracy(selected_generator, g_test_loader, device=device)\n",
    "\n",
    "print(f'Final model accuracy on train data: {train_acc:.3f}')\n",
    "print(f'Final model accuracy on val data: {val_acc:.3f}')\n",
    "print(f'Final model accuracy on test data: {test_acc:.3f}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:13:37.979715Z",
     "iopub.execute_input": "2024-05-02T10:13:37.980102Z",
     "iopub.status.idle": "2024-05-02T10:14:03.127873Z",
     "shell.execute_reply.started": "2024-05-02T10:13:37.980073Z",
     "shell.execute_reply": "2024-05-02T10:14:03.126969Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:11:26.529939400Z",
     "start_time": "2024-05-02T11:10:39.237810900Z"
    }
   },
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model accuracy on train data: 0.166\n",
      "Final model accuracy on val data: 0.161\n",
      "Final model accuracy on test data: 0.191\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text_input = ['can', 'you', 'feel', 'the']\n",
    "\" \".join(beam_search(text_input, selected_generator))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:08:34.471004Z",
     "iopub.execute_input": "2024-05-02T10:08:34.471933Z",
     "iopub.status.idle": "2024-05-02T10:08:35.174017Z",
     "shell.execute_reply.started": "2024-05-02T10:08:34.471890Z",
     "shell.execute_reply": "2024-05-02T10:08:35.173131Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:11:26.980949300Z",
     "start_time": "2024-05-02T11:11:26.527978100Z"
    }
   },
   "execution_count": 191,
   "outputs": [
    {
     "data": {
      "text/plain": "'can you feel the old man of the'"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text_input = ['sometimes', 'i', 'try']\n",
    "\" \".join(beam_search(text_input, selected_generator))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:08:38.507852Z",
     "iopub.execute_input": "2024-05-02T10:08:38.508781Z",
     "iopub.status.idle": "2024-05-02T10:08:39.481529Z",
     "shell.execute_reply.started": "2024-05-02T10:08:38.508748Z",
     "shell.execute_reply": "2024-05-02T10:08:39.480662Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:11:27.268302200Z",
     "start_time": "2024-05-02T11:11:26.979947100Z"
    }
   },
   "execution_count": 192,
   "outputs": [
    {
     "data": {
      "text/plain": "'sometimes i try to be a man'"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text_input = ['when', 'i', 'can']\n",
    "\" \".join(beam_search(text_input, selected_generator))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:08:41.610774Z",
     "iopub.execute_input": "2024-05-02T10:08:41.611574Z",
     "iopub.status.idle": "2024-05-02T10:08:42.348974Z",
     "shell.execute_reply.started": "2024-05-02T10:08:41.611539Z",
     "shell.execute_reply": "2024-05-02T10:08:42.348010Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:11:27.630726Z",
     "start_time": "2024-05-02T11:11:27.264679200Z"
    }
   },
   "execution_count": 193,
   "outputs": [
    {
     "data": {
      "text/plain": "'when i can t come to be'"
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text_input = ['the', 'man', 'was']\n",
    "\" \".join(beam_search(text_input, selected_generator))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:08:45.638436Z",
     "iopub.execute_input": "2024-05-02T10:08:45.638768Z",
     "iopub.status.idle": "2024-05-02T10:08:46.339935Z",
     "shell.execute_reply.started": "2024-05-02T10:08:45.638744Z",
     "shell.execute_reply": "2024-05-02T10:08:46.339049Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:11:27.870021300Z",
     "start_time": "2024-05-02T11:11:27.627611400Z"
    }
   },
   "execution_count": 194,
   "outputs": [
    {
     "data": {
      "text/plain": "'the man was a man of the'"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text_input = ['at', 'the', 'sea']\n",
    "\" \".join(beam_search(text_input, selected_generator, num_predictions=5))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:08:50.346447Z",
     "iopub.execute_input": "2024-05-02T10:08:50.346807Z",
     "iopub.status.idle": "2024-05-02T10:08:51.517448Z",
     "shell.execute_reply.started": "2024-05-02T10:08:50.346779Z",
     "shell.execute_reply": "2024-05-02T10:08:51.516492Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:11:28.324292300Z",
     "start_time": "2024-05-02T11:11:27.868933100Z"
    }
   },
   "execution_count": 195,
   "outputs": [
    {
     "data": {
      "text/plain": "'at the sea of the old man s'"
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text_input = ['the', 'season']\n",
    "\" \".join(beam_search(text_input, selected_generator, num_predictions=5))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:08:54.047849Z",
     "iopub.execute_input": "2024-05-02T10:08:54.048524Z",
     "iopub.status.idle": "2024-05-02T10:08:54.947679Z",
     "shell.execute_reply.started": "2024-05-02T10:08:54.048490Z",
     "shell.execute_reply": "2024-05-02T10:08:54.946793Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:11:28.769134700Z",
     "start_time": "2024-05-02T11:11:28.318806200Z"
    }
   },
   "execution_count": 196,
   "outputs": [
    {
     "data": {
      "text/plain": "'the season in the midst of the'"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text_input = ['the', 'hand']\n",
    "\" \".join(beam_search(text_input, selected_generator, num_predictions=8, beam_width=4))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:09:00.348502Z",
     "iopub.execute_input": "2024-05-02T10:09:00.349172Z",
     "iopub.status.idle": "2024-05-02T10:09:01.910476Z",
     "shell.execute_reply.started": "2024-05-02T10:09:00.349140Z",
     "shell.execute_reply": "2024-05-02T10:09:01.909566Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:11:29.220100600Z",
     "start_time": "2024-05-02T11:11:28.767524600Z"
    }
   },
   "execution_count": 197,
   "outputs": [
    {
     "data": {
      "text/plain": "'the hand of the old man who had been a'"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text_input = ['sometimes', 'when', 'i']\n",
    "\" \".join(beam_search(text_input, selected_generator, num_predictions=8, beam_width=3))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:09:04.647888Z",
     "iopub.execute_input": "2024-05-02T10:09:04.648559Z",
     "iopub.status.idle": "2024-05-02T10:09:05.600002Z",
     "shell.execute_reply.started": "2024-05-02T10:09:04.648528Z",
     "shell.execute_reply": "2024-05-02T10:09:05.599111Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:11:29.704066900Z",
     "start_time": "2024-05-02T11:11:29.217754900Z"
    }
   },
   "execution_count": 198,
   "outputs": [
    {
     "data": {
      "text/plain": "'sometimes when i m not to be a man of the'"
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text_input = ['cold']\n",
    "\" \".join(beam_search(text_input, selected_generator))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:06:51.615639Z",
     "iopub.execute_input": "2024-05-02T10:06:51.616290Z",
     "iopub.status.idle": "2024-05-02T10:06:52.309541Z",
     "shell.execute_reply.started": "2024-05-02T10:06:51.616257Z",
     "shell.execute_reply": "2024-05-02T10:06:52.308562Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:11:29.965781500Z",
     "start_time": "2024-05-02T11:11:29.699471100Z"
    }
   },
   "execution_count": 199,
   "outputs": [
    {
     "data": {
      "text/plain": "'cold old man and the'"
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text_input = ['it', 'was', 'a', 'dark']\n",
    "\" \".join(beam_search(text_input, selected_generator))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:10:02.087896Z",
     "iopub.execute_input": "2024-05-02T10:10:02.088575Z",
     "iopub.status.idle": "2024-05-02T10:10:03.060003Z",
     "shell.execute_reply.started": "2024-05-02T10:10:02.088540Z",
     "shell.execute_reply": "2024-05-02T10:10:03.059036Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:11:30.341283400Z",
     "start_time": "2024-05-02T11:11:29.962540700Z"
    }
   },
   "execution_count": 200,
   "outputs": [
    {
     "data": {
      "text/plain": "'it was a dark man of a man'"
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text_input = ['this', 'isn', 't' ,'going']\n",
    "\" \".join(beam_search(text_input, selected_generator))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:10:07.330729Z",
     "iopub.execute_input": "2024-05-02T10:10:07.331078Z",
     "iopub.status.idle": "2024-05-02T10:10:08.017936Z",
     "shell.execute_reply.started": "2024-05-02T10:10:07.331034Z",
     "shell.execute_reply": "2024-05-02T10:10:08.017102Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:11:30.626717100Z",
     "start_time": "2024-05-02T11:11:30.340079600Z"
    }
   },
   "execution_count": 201,
   "outputs": [
    {
     "data": {
      "text/plain": "'this isn t going to be a man'"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text_input = ['the', 'woman', 'took', 'the', 'cat']\n",
    "\" \".join(beam_search(text_input, selected_generator))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:16:30.509775Z",
     "iopub.execute_input": "2024-05-02T10:16:30.510177Z",
     "iopub.status.idle": "2024-05-02T10:16:31.206800Z",
     "shell.execute_reply.started": "2024-05-02T10:16:30.510146Z",
     "shell.execute_reply": "2024-05-02T10:16:31.205844Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:11:31.062381900Z",
     "start_time": "2024-05-02T11:11:30.621323800Z"
    }
   },
   "execution_count": 202,
   "outputs": [
    {
     "data": {
      "text/plain": "'the woman took the cat in the depths of'"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'i cannot believe it is a man of the old man and a man who had been a'"
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input = ['i', 'cannot', 'believe']\n",
    "\" \".join(beam_search(text_input, selected_generator, 15))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:11:32.519154500Z",
     "start_time": "2024-05-02T11:11:31.022256700Z"
    }
   },
   "execution_count": 203
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experimenting with all models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def test_all_models(models, names, text, num_predictions=7, beam_width=5):\n",
    "    for idx in range(len(models)):\n",
    "        print(f'Generating {num_predictions} with model {names[idx]} and beam width {beam_width}')\n",
    "        words = beam_search(text, models[idx], num_predictions, beam_width)\n",
    "        print(' '.join(words))\n",
    "        print()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:11:52.565319Z",
     "iopub.execute_input": "2024-05-02T10:11:52.565751Z",
     "iopub.status.idle": "2024-05-02T10:11:52.571280Z",
     "shell.execute_reply.started": "2024-05-02T10:11:52.565717Z",
     "shell.execute_reply": "2024-05-02T10:11:52.570272Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:11:32.539615300Z",
     "start_time": "2024-05-02T11:11:32.517678900Z"
    }
   },
   "execution_count": 204,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "text = ['the', 'doctor', 'had']\n",
    "test_all_models(generation_models, generation_names, text)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:16:56.469278Z",
     "iopub.execute_input": "2024-05-02T10:16:56.469638Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T11:11:44.768485Z",
     "start_time": "2024-05-02T11:11:32.527438700Z"
    }
   },
   "execution_count": 205,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 7 with model Basiclr_0.001_e50 and beam width 5\n",
      "the doctor had been in the midst of the other\n",
      "\n",
      "Generating 7 with model Basiclr_0.005_e40 and beam width 5\n",
      "the doctor had been in the middle of us and\n",
      "\n",
      "Generating 7 with model BasicWlr_0.001_e50 and beam width 5\n",
      "the doctor had been in front of the rear of\n",
      "\n",
      "Generating 7 with model BasicWlr_0.005_e40 and beam width 5\n",
      "the doctor had been no more of us in the\n",
      "\n",
      "Generating 7 with model Deeperlr_0.001_e50 and beam width 5\n",
      "the doctor had been in the ground of the ground\n",
      "\n",
      "Generating 7 with model Deeperlr_0.005_e40 and beam width 5\n",
      "the doctor had the man of the trench of the\n",
      "\n",
      "Generating 7 with model DeeperWlr_0.001_e50 and beam width 5\n",
      "the doctor had is a man of the head of\n",
      "\n",
      "Generating 7 with model DeeperWlr_0.005_e40 and beam width 5\n",
      "the doctor had are t see that we are t\n",
      "\n",
      "Generating 7 with model Dropoutlr_0.001_e50 and beam width 5\n",
      "the doctor had been in the ground of the other\n",
      "\n",
      "Generating 7 with model Dropoutlr_0.005_e40 and beam width 5\n",
      "the doctor had been to be in the other of\n",
      "\n",
      "Generating 7 with model DropoutWlr_0.001_e50 and beam width 5\n",
      "the doctor had been a little man of the same\n",
      "\n",
      "Generating 7 with model DropoutWlr_0.005_e40 and beam width 5\n",
      "the doctor had been a man of the ground of\n",
      "\n",
      "Generating 7 with model Mediumlr_0.001_e50 and beam width 5\n",
      "the doctor had been seen in the ground of the\n",
      "\n",
      "Generating 7 with model Mediumlr_0.005_e40 and beam width 5\n",
      "the doctor had been seen in the ground of the\n",
      "\n",
      "Generating 7 with model MediumWlr_0.001_e50 and beam width 5\n",
      "the doctor had been seen in the ground of the\n",
      "\n",
      "Generating 7 with model MediumWlr_0.005_e40 and beam width 5\n",
      "the doctor had been in the same man of the\n"
     ]
    }
   ]
  }
 ]
}
